{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b46e5896-cda4-4d0a-8579-16f9e33b6aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyworld as pw\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "from pymcd.mcd import Calculate_MCD\n",
    "import audio as Audio\n",
    "# wav2vecSER Model\n",
    "from speechbrain.inference.interfaces import foreign_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b303642-afb2-4879-8721-7157a02a0fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['925', '1632', '1924', '466', '1804', '2515', '1155', '905', '1391', '718', '1311', '2524', '1645', '122', '1471', '1918', '867', '1614', '3', '382', '339', '1306', '1233', '1671', '661', '79', '1440', '2309', '1360', '2382', '2529', '236', '1735', '1848', '1193', '557', '470', '1406', '1257', '1831', '440', '1535', '1942', '1363', '2408', '247', '2514', '1180', '221', '115', '1764', '2145', '2417', '1758', '1403', '172', '472', '2459', '47', '283', '362', '800', '465', '1282', '1905', '1927', '2052', '1944', '2349', '40', '782', '2263', '1622', '1514', '54', '1435', '1850', '1602', '451', '1510', '2131', '20', '119', '2489', '2266', '2438', '2015', '1865', '2149', '1542', '766', '2447', '2304', '1068', '1815', '2016', '2273', '1873', '1947', '404', '759', '2406', '622', '712', '1485', '1953', '1625', '2497', '1854', '1102', '1774', '1516', '2400', '1780', '962', '749', '1553', '1190', '295', '1368', '855', '24', '2347', '1531', '168', '896', '280', '1394', '1108', '189', '856', '1750', '1889', '1630', '597', '794', '1222', '2470', '1884', '213', '1075', '299', '1289', '1017', '1262', '777', '1434', '1248', '1533', '1722', '318', '1621', '1156', '1404', '1597', '2216', '1529', '2075', '753', '865', '114', '2294', '2511', '1226', '2077', '2184', '1856', '250', '102', '1562', '1371', '954', '1503', '1806', '218', '279', '707', '851', '2183', '1414', '1653', '1717', '87', '1577', '2', '1937', '520', '222', '970', '872', '314', '534', '1922', '2236', '1817', '521', '1700', '586', '2210', '2046', '96']\n"
     ]
    }
   ],
   "source": [
    "ground_truth_path = \"/home/johnny9696/Desktop/DATA/dailytalk_resample/data\"\n",
    "#model_output_path = \"/mnt/hdd_storage/di_fit_tts_output/output/dailytalk\"\n",
    "#model_output_path = \"/mnt/hdd_storage/di_fit_tts_output/output/Fitted_v19_flowv2_MPE\"\n",
    "model_output_path = \"/mnt/hdd_storage/FCtalkeroutput/result/Dailytalk/400000\"\n",
    "sampling_rate = 22050\n",
    "hop_length = 256\n",
    "d_list = os.listdir(model_output_path)\n",
    "print(d_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d61602b-6afc-4b31-a39a-7ae7e4c166fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pitch(wav, sampling_rate = 22050, hop_length = 256):\n",
    "    pitch, t = pw.dio(\n",
    "        wav.astype(np.float64),\n",
    "        sampling_rate,\n",
    "        frame_period=hop_length / sampling_rate * 1000,\n",
    "    )\n",
    "    pitch = pw.stonemask(wav.astype(np.float64), pitch, t, sampling_rate)\n",
    "    return pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ee9ca55-d886-4df8-b84d-92d64286ee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_energy(wav):\n",
    "# Compute mel-scale spectrogram and energy\n",
    "        STFT = Audio.stft.TacotronSTFT(\n",
    "            1024,\n",
    "            256,\n",
    "            1024,\n",
    "            80,\n",
    "            22050,\n",
    "            0,\n",
    "            8000,\n",
    "        )\n",
    "        _, energy = Audio.tools.get_mel_from_wav(wav, STFT)\n",
    "        return energy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82871de6-ea07-4ea4-b189-cc94fac2edea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182431/3671593932.py:24: RuntimeWarning: divide by zero encountered in log\n",
      "  gt_log = np.nan_to_num(np.log(gt_p))\n",
      "/tmp/ipykernel_182431/3671593932.py:25: RuntimeWarning: divide by zero encountered in log\n",
      "  gen_log = np.nan_to_num(np.log(gen_p))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.2658961653576722\n",
      "200 0.2870150289077375\n",
      "300 0.2864429711792225\n",
      "400 0.2834567216332175\n",
      "500 0.28545050395960286\n",
      "600 0.28467967677665224\n",
      "700 0.28458208459691653\n",
      "800 0.2827286184511375\n",
      "900 0.28385097066413056\n",
      "1000 0.28225884502668924\n",
      "1100 0.2829633249238295\n",
      "1200 0.2839483250226523\n",
      "1300 0.28484046923839057\n",
      "1400 0.2852755388117444\n",
      "1500 0.28378207342966283\n",
      "1600 0.28296229263296807\n",
      "1700 0.2827688870045572\n",
      "1800 0.2834997786057117\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "wav_rmse = 0\n",
    "f0_rmse = 0\n",
    "for i in d_list:\n",
    "    t_output_path = os.path.join(model_output_path, i)\n",
    "    t_gt_path = os.path.join(ground_truth_path, i)\n",
    "    w_list = os.listdir(t_output_path)\n",
    "    for wav_name in w_list:\n",
    "        if wav_name[-3:] !=\"wav\":\n",
    "            continue\n",
    "        gt_wav, sr = librosa.load(os.path.join(t_gt_path, wav_name))\n",
    "        gen_wav, sr = librosa.load(os.path.join(t_output_path, wav_name))\n",
    "        gt_p = get_pitch(gt_wav)\n",
    "        gen_p = get_pitch(gen_wav)\n",
    "        if len(gt_p) > len(gen_p):\n",
    "            gap = len(gt_p) - len(gen_p)\n",
    "            gt_p = gt_p[gap//2:-gap//2]\n",
    "            gen_p = gen_p[:len(gt_p)]\n",
    "        else:\n",
    "            gap = len(gen_p) - len(gt_p)\n",
    "            gen_p = gen_p[gap//2:-gap//2]\n",
    "            gt_p = gt_p[:len(gt_p)]\n",
    "        try:\n",
    "            gt_log = np.nan_to_num(np.log(gt_p))\n",
    "            gen_log = np.nan_to_num(np.log(gen_p))\n",
    "            error = abs(gt_log-gen_log)\n",
    "            non_inf_counter = 0\n",
    "            rmse = 0\n",
    "            for data in error:\n",
    "                if data != np.inf and data != -np.inf and data>= -10 and data <=10:\n",
    "                    non_inf_counter += 1\n",
    "                    rmse += data ** 2\n",
    "            rmse = np.sqrt(rmse/non_inf_counter)\n",
    "            f0_rmse += rmse\n",
    "            count += 1\n",
    "            if count%100 == 0:\n",
    "                print(count, f0_rmse/count)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37fb272f-bcd5-470b-9cba-87bc66f35168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28331581326821015\n"
     ]
    }
   ],
   "source": [
    "print(f0_rmse/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7884b0fc-50b6-4163-ac4b-51f466aba642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 2.196185207645344\n",
      "200 2.1023203274443647\n",
      "300 2.105583265324168\n",
      "400 2.1052756804779196\n",
      "500 2.126343371245231\n",
      "600 2.1122294199925498\n",
      "700 2.1512656105082058\n",
      "800 2.1650692535905325\n",
      "900 2.1802140684437066\n",
      "1000 2.1810079052097717\n",
      "1100 2.1940237059304404\n",
      "1200 2.185749640860426\n",
      "1300 2.1810806921692705\n",
      "1400 2.1843413640504883\n",
      "1500 2.1900886420076153\n",
      "1600 2.187774498195226\n",
      "1700 2.193582413338476\n",
      "1800 2.195826562222065\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "e_rmse = 0\n",
    "for i in d_list:\n",
    "    t_output_path = os.path.join(model_output_path, i)\n",
    "    t_gt_path = os.path.join(ground_truth_path, i)\n",
    "    w_list = os.listdir(t_output_path)\n",
    "    for wav_name in w_list:\n",
    "        if wav_name[-3:] !=\"wav\":\n",
    "            continue\n",
    "        gt_wav, sr = librosa.load(os.path.join(t_gt_path, wav_name))\n",
    "        gen_wav, sr = librosa.load(os.path.join(t_output_path, wav_name))\n",
    "        gt_p = get_energy(gt_wav)\n",
    "        gen_p = get_energy(gen_wav)\n",
    "        if len(gt_p) > len(gen_p):\n",
    "            gap = len(gt_p) - len(gen_p)\n",
    "            gt_p = gt_p[gap//2:-gap//2]\n",
    "            gen_p = gen_p[:len(gt_p)]\n",
    "        else:\n",
    "            gap = len(gen_p) - len(gt_p)\n",
    "            gen_p = gen_p[gap//2:-gap//2]\n",
    "            gt_p = gt_p[:len(gt_p)]\n",
    "        try:\n",
    "            gt_log = np.nan_to_num(np.log(gt_p))\n",
    "            gen_log = np.nan_to_num(np.log(gen_p))\n",
    "            error = abs(gt_log-gen_log)\n",
    "            non_inf_counter = 0\n",
    "            rmse = 0\n",
    "            for data in error:\n",
    "                if data != np.inf and data != -np.inf and data>= -10 and data <=10:\n",
    "                    non_inf_counter += 1\n",
    "                    rmse += data ** 2\n",
    "            rmse = np.sqrt(rmse/non_inf_counter)\n",
    "            e_rmse += rmse\n",
    "            count += 1\n",
    "            if count%100 == 0:\n",
    "                print(count, e_rmse/count)\n",
    "\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43da55ed-901a-4548-92ca-79f53cee7ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1974557296907156\n"
     ]
    }
   ],
   "source": [
    "print(e_rmse/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06bd8372-97c9-4439-a04d-1816630c15ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johnny9696/anaconda3/envs/FS2/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/johnny9696/anaconda3/envs/FS2/lib/python3.8/site-packages/transformers/configuration_utils.py:364: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
     ]
    }
   ],
   "source": [
    "audio_embedder = foreign_class(source=\"speechbrain/emotion-recognition-wav2vec2-IEMOCAP\",\n",
    "                                       pymodule_file=\"custom_interface.py\", classname=\"CustomEncoderWav2vec2Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ecc979f-9b3c-497a-a651-6b726640afd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.7523511265218258\n",
      "200 0.7925460959598422\n",
      "300 0.815978451197346\n",
      "400 0.8201917089149355\n",
      "500 0.8300481767952442\n",
      "600 0.84527173054715\n",
      "700 0.8470515032006162\n",
      "800 0.8432549473736435\n",
      "900 0.8562097896138827\n",
      "1000 0.8494314231425524\n",
      "1100 0.850031384310939\n",
      "1200 0.8466727622846763\n",
      "1300 0.8569757173038446\n",
      "1400 0.8603087292398726\n",
      "1500 0.8606329367558161\n",
      "1600 0.8579823982156813\n",
      "1700 0.8616107411945567\n",
      "1800 0.8608355258570777\n"
     ]
    }
   ],
   "source": [
    "w_count = 0\n",
    "wav_rmse = 0\n",
    "for i in d_list:\n",
    "    t_output_path = os.path.join(model_output_path, i)\n",
    "    t_gt_path = os.path.join(ground_truth_path, i)\n",
    "    w_list = os.listdir(t_output_path)\n",
    "    for wav_name in w_list:\n",
    "        if wav_name[-3:] !=\"wav\":\n",
    "            continue\n",
    "        gt_wav, sr = librosa.load(os.path.join(t_gt_path, wav_name))\n",
    "        gen_wav, sr = librosa.load(os.path.join(t_output_path, wav_name))\n",
    "        gt_wav_e = torch.tensor(gt_wav)\n",
    "        gt_wav_emb = audio_embedder.encode_batch(gt_wav_e)\n",
    "        gt_wav_emb = np.array(gt_wav_emb.squeeze(0))\n",
    "        gen_wav_e = torch.tensor(gen_wav)\n",
    "        gen_wav_emb = audio_embedder.encode_batch(gen_wav_e)\n",
    "        gen_wav_emb = np.array(gen_wav_emb.squeeze(0))\n",
    "        error = abs(gt_wav_emb - gen_wav_emb)\n",
    "        rmse = np.sqrt(np.mean(error**2))\n",
    "        wav_rmse += rmse\n",
    "        w_count += 1\n",
    "        if w_count%100 == 0:\n",
    "            print(w_count, wav_rmse/w_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6a316af-1703-457c-915c-1a4d476e5ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8607784777069869\n"
     ]
    }
   ],
   "source": [
    "print(wav_rmse/w_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6d08dd5-fd74-49b4-af10-6db010771de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 10.10660770587426\n",
      "200 10.10888024645096\n",
      "300 10.011493968878957\n",
      "400 10.09085413362799\n",
      "500 10.043320922660788\n",
      "600 9.96831578403074\n",
      "700 10.003423483188122\n",
      "800 9.945544226302438\n",
      "900 9.890263770035775\n",
      "1000 9.878555149917473\n",
      "1100 9.948725505183795\n",
      "1200 9.929925120825986\n",
      "1300 9.929186197460687\n",
      "1400 9.926300914123285\n",
      "1500 9.956359295617505\n",
      "1600 9.923667209757577\n",
      "1700 9.908956793568363\n",
      "1800 9.914939443629109\n"
     ]
    }
   ],
   "source": [
    "mcd_count = 0\n",
    "mcd = 0\n",
    "mcd_toolbox = Calculate_MCD(MCD_mode=\"dtw\")\n",
    "for i in d_list:\n",
    "    t_output_path = os.path.join(model_output_path, i)\n",
    "    t_gt_path = os.path.join(ground_truth_path, i)\n",
    "    w_list = os.listdir(t_output_path)\n",
    "    for wav_name in w_list:\n",
    "        if wav_name[-3:] !=\"wav\":\n",
    "            continue\n",
    "        mcd_value = mcd_toolbox.calculate_mcd(os.path.join(t_gt_path, wav_name), os.path.join(t_output_path, wav_name))\n",
    "        mcd += mcd_value\n",
    "        mcd_count += 1\n",
    "        if mcd_count % 100 == 0:\n",
    "            print(mcd_count, mcd/mcd_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ce4fbb8-a292-4d29-b830-3be608a57260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1840 9.907362612219272\n"
     ]
    }
   ],
   "source": [
    "print(mcd_count, mcd/mcd_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6821f85a-e313-4369-ae6c-77ef0039a165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
