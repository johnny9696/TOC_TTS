{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b46e5896-cda4-4d0a-8579-16f9e33b6aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyworld as pw\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "from pymcd.mcd import Calculate_MCD\n",
    "import audio as Audio\n",
    "# wav2vecSER Model\n",
    "from speechbrain.inference.interfaces import foreign_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b303642-afb2-4879-8721-7157a02a0fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['925', '1632', '1924', '466', '1804', '2515', '1155', '905', '1391', '718', '1311', '2524', '1645', '122', '1471', '1918', '867', '1614', '3', '382', '339', '1306', '1233', '1671', '661', '79', '1440', '2309', '1360', '2382', '2529', '236', '1735', '1848', '1193', '557', '470', '1406', '1257', '1831', '440', '1535', '1942', '1363', '2408', '247', '2514', '1180', '221', '115', '1764', '2145', '2417', '1758', '1403', '172', '472', '2459', '47', '283', '362', '800', '465', '1282', '1905', '1927', '2052', '1944', '2349', '40', '782', '2263', '1622', '1514', '54', '1435', '1850', '1602', '451', '1510', '2131', '20', '119', '2489', '2266', '2438', '2015', '1865', '2149', '1542', '766', '2447', '2304', '1068', '1815', '2016', '2273', '1873', '1947', '404', '759', '2406', '622', '712', '1485', '1953', '1625', '2497', '1854', '1102', '1774', '1516', '2400', '1780', '962', '749', '1553', '1190', '295', '1368', '855', '24', '2347', '1531', '168', '896', '280', '1394', '1108', '189', '856', '1750', '1889', '1630', '597', '794', '1222', '2470', '1884', '213', '1075', '299', '1289', '1017', '1262', '777', '1434', '1248', '1533', '1722', '318', '1621', '1156', '1404', '1597', '2216', '1529', '2075', '753', '865', '114', '2294', '2511', '1226', '2077', '2184', '1856', '250', '102', '1562', '954', '1503', '1806', '218', '279', '707', '851', '2183', '1414', '1653', '1717', '87', '1577', '2', '1937', '520', '222', '970', '872', '314', '534', '1922', '2236', '1817', '521', '1700', '586', '2210', '2046', '96']\n"
     ]
    }
   ],
   "source": [
    "ground_truth_path = \"/home/johnny9696/Desktop/DATA/dailytalk_resample/data\"\n",
    "#model_output_path = \"/mnt/hdd_storage/di_fit_tts_output/output/dailytalk\"\n",
    "#model_output_path = \"/mnt/hdd_storage/di_fit_tts_output/output/Fitted_v19_flowv2_MPE\"\n",
    "model_output_path = \"/mnt/hdd_storage/di_fit_tts_output/output/dailytalk\"\n",
    "sampling_rate = 22050\n",
    "hop_length = 256\n",
    "d_list = os.listdir(model_output_path)\n",
    "print(d_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d61602b-6afc-4b31-a39a-7ae7e4c166fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pitch(wav, sampling_rate = 22050, hop_length = 256):\n",
    "    pitch, t = pw.dio(\n",
    "        wav.astype(np.float64),\n",
    "        sampling_rate,\n",
    "        frame_period=hop_length / sampling_rate * 1000,\n",
    "    )\n",
    "    pitch = pw.stonemask(wav.astype(np.float64), pitch, t, sampling_rate)\n",
    "    return pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ee9ca55-d886-4df8-b84d-92d64286ee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_energy(wav):\n",
    "# Compute mel-scale spectrogram and energy\n",
    "        STFT = Audio.stft.TacotronSTFT(\n",
    "            1024,\n",
    "            256,\n",
    "            1024,\n",
    "            80,\n",
    "            22050,\n",
    "            0,\n",
    "            8000,\n",
    "        )\n",
    "        _, energy = Audio.tools.get_mel_from_wav(wav, STFT)\n",
    "        return energy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82871de6-ea07-4ea4-b189-cc94fac2edea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_94240/3240988841.py:24: RuntimeWarning: divide by zero encountered in log\n",
      "  gt_log = np.nan_to_num(np.log(gt_p))\n",
      "/tmp/ipykernel_94240/3240988841.py:25: RuntimeWarning: divide by zero encountered in log\n",
      "  gen_log = np.nan_to_num(np.log(gen_p))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.25865553722809814\n",
      "200 0.27163505877259014\n",
      "300 0.2693354819566689\n",
      "400 0.26869025774813915\n",
      "500 0.27242750002260435\n",
      "600 0.2727722910198881\n",
      "700 0.2698624748030164\n",
      "800 0.2685931600261765\n",
      "900 0.2704759382665826\n",
      "1000 0.26997689959976184\n",
      "1100 0.2740851436821451\n",
      "1200 0.27410256845130765\n",
      "1300 0.2734715120202252\n",
      "1400 0.2726896280622447\n",
      "1500 0.27210604424624\n",
      "1600 0.2721983646085162\n",
      "1700 0.2722425866012488\n",
      "1800 0.27216503515425894\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "wav_rmse = 0\n",
    "f0_rmse = 0\n",
    "for i in d_list:\n",
    "    t_output_path = os.path.join(model_output_path, i)\n",
    "    t_gt_path = os.path.join(ground_truth_path, i[1:])\n",
    "    w_list = os.listdir(t_output_path)\n",
    "    for wav_name in w_list:\n",
    "        if wav_name[-3:] !=\"wav\":\n",
    "            continue\n",
    "        gt_wav, sr = librosa.load(os.path.join(t_gt_path, wav_name))\n",
    "        gen_wav, sr = librosa.load(os.path.join(t_output_path, wav_name))\n",
    "        gt_p = get_pitch(gt_wav)\n",
    "        gen_p = get_pitch(gen_wav)\n",
    "        if len(gt_p) > len(gen_p):\n",
    "            gap = len(gt_p) - len(gen_p)\n",
    "            gt_p = gt_p[gap//2:-gap//2]\n",
    "            gen_p = gen_p[:len(gt_p)]\n",
    "        else:\n",
    "            gap = len(gen_p) - len(gt_p)\n",
    "            gen_p = gen_p[gap//2:-gap//2]\n",
    "            gt_p = gt_p[:len(gt_p)]\n",
    "        try:\n",
    "            gt_log = np.nan_to_num(np.log(gt_p))\n",
    "            gen_log = np.nan_to_num(np.log(gen_p))\n",
    "            error = abs(gt_log-gen_log)\n",
    "            non_inf_counter = 0\n",
    "            rmse = 0\n",
    "            for data in error:\n",
    "                if data != np.inf and data != -np.inf and data>= -10 and data <=10:\n",
    "                    non_inf_counter += 1\n",
    "                    rmse += data ** 2\n",
    "            rmse = np.sqrt(rmse/non_inf_counter)\n",
    "            f0_rmse += rmse\n",
    "            count += 1\n",
    "            if count%100 == 0:\n",
    "                print(count, f0_rmse/count)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37fb272f-bcd5-470b-9cba-87bc66f35168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27358981651310077\n"
     ]
    }
   ],
   "source": [
    "print(f0_rmse/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7884b0fc-50b6-4163-ac4b-51f466aba642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 2.3185399637676203\n",
      "200 2.271798993704666\n",
      "300 2.246603476359974\n",
      "400 2.2954430475821996\n",
      "500 2.2930710966871497\n",
      "600 2.2944573930442163\n",
      "700 2.2937272719744835\n",
      "800 2.2665241327009173\n",
      "900 2.2621018848761123\n",
      "1000 2.2623928438029215\n",
      "1100 2.2652582863789483\n",
      "1200 2.2855105738931227\n",
      "1300 2.2843313161903853\n",
      "1400 2.2783871658314987\n",
      "1500 2.2901144045854225\n",
      "1600 2.3056090099830917\n",
      "1700 2.3000032527488656\n",
      "1800 2.290041916358195\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "e_rmse = 0\n",
    "for i in d_list:\n",
    "    t_output_path = os.path.join(model_output_path, i)\n",
    "    t_gt_path = os.path.join(ground_truth_path, i[1:])\n",
    "    w_list = os.listdir(t_output_path)\n",
    "    for wav_name in w_list:\n",
    "        if wav_name[-3:] !=\"wav\":\n",
    "            continue\n",
    "        gt_wav, sr = librosa.load(os.path.join(t_gt_path, wav_name))\n",
    "        gen_wav, sr = librosa.load(os.path.join(t_output_path, wav_name))\n",
    "        gt_p = get_energy(gt_wav)\n",
    "        gen_p = get_energy(gen_wav)\n",
    "        if len(gt_p) > len(gen_p):\n",
    "            gap = len(gt_p) - len(gen_p)\n",
    "            gt_p = gt_p[gap//2:-gap//2]\n",
    "            gen_p = gen_p[:len(gt_p)]\n",
    "        else:\n",
    "            gap = len(gen_p) - len(gt_p)\n",
    "            gen_p = gen_p[gap//2:-gap//2]\n",
    "            gt_p = gt_p[:len(gt_p)]\n",
    "        try:\n",
    "            gt_log = np.nan_to_num(np.log(gt_p))\n",
    "            gen_log = np.nan_to_num(np.log(gen_p))\n",
    "            error = abs(gt_log-gen_log)\n",
    "            non_inf_counter = 0\n",
    "            rmse = 0\n",
    "            for data in error:\n",
    "                if data != np.inf and data != -np.inf and data>= -10 and data <=10:\n",
    "                    non_inf_counter += 1\n",
    "                    rmse += data ** 2\n",
    "            rmse = np.sqrt(rmse/non_inf_counter)\n",
    "            e_rmse += rmse\n",
    "            count += 1\n",
    "            if count%100 == 0:\n",
    "                print(count, e_rmse/count)\n",
    "\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43da55ed-901a-4548-92ca-79f53cee7ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2857055624878075\n"
     ]
    }
   ],
   "source": [
    "print(e_rmse/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06bd8372-97c9-4439-a04d-1816630c15ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
     ]
    }
   ],
   "source": [
    "audio_embedder = foreign_class(source=\"speechbrain/emotion-recognition-wav2vec2-IEMOCAP\",\n",
    "                                       pymodule_file=\"custom_interface.py\", classname=\"CustomEncoderWav2vec2Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ecc979f-9b3c-497a-a651-6b726640afd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.7813318032026291\n",
      "200 0.7770105202496052\n",
      "300 0.755288302898407\n",
      "400 0.7489365226402879\n",
      "500 0.7561649296879769\n",
      "600 0.7581666740278403\n",
      "700 0.7590387346063341\n",
      "800 0.7457714810129255\n",
      "900 0.7501404679235485\n",
      "1000 0.7519019912555813\n",
      "1100 0.7541129228811373\n",
      "1200 0.7518807866175969\n",
      "1300 0.7586494358514364\n",
      "1400 0.7618235496538026\n",
      "1500 0.7629914500117302\n",
      "1600 0.762681849161163\n",
      "1700 0.7616467028856277\n",
      "1800 0.7605984793851773\n"
     ]
    }
   ],
   "source": [
    "w_count = 0\n",
    "wav_rmse = 0\n",
    "for i in d_list:\n",
    "    t_output_path = os.path.join(model_output_path, i)\n",
    "    t_gt_path = os.path.join(ground_truth_path, i)\n",
    "    w_list = os.listdir(t_output_path)\n",
    "    for wav_name in w_list:\n",
    "        if wav_name[-3:] !=\"wav\":\n",
    "            continue\n",
    "        gt_wav, sr = librosa.load(os.path.join(t_gt_path, wav_name))\n",
    "        gen_wav, sr = librosa.load(os.path.join(t_output_path, wav_name))\n",
    "        gt_wav_e = torch.tensor(gt_wav)\n",
    "        gt_wav_emb = audio_embedder.encode_batch(gt_wav_e)\n",
    "        gt_wav_emb = np.array(gt_wav_emb.squeeze(0))\n",
    "        gen_wav_e = torch.tensor(gen_wav)\n",
    "        gen_wav_emb = audio_embedder.encode_batch(gen_wav_e)\n",
    "        gen_wav_emb = np.array(gen_wav_emb.squeeze(0))\n",
    "        error = abs(gt_wav_emb - gen_wav_emb)\n",
    "        rmse = np.sqrt(np.mean(error**2))\n",
    "        wav_rmse += rmse\n",
    "        w_count += 1\n",
    "        if w_count%100 == 0:\n",
    "            print(w_count, wav_rmse/w_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6a316af-1703-457c-915c-1a4d476e5ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7613215082088403\n"
     ]
    }
   ],
   "source": [
    "print(wav_rmse/w_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6d08dd5-fd74-49b4-af10-6db010771de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 7.837274787418521\n",
      "200 7.783389956527858\n",
      "300 7.607149453781307\n",
      "400 7.71399402305241\n",
      "500 7.702864844713825\n",
      "600 7.590505965616717\n",
      "700 7.667577334033091\n",
      "800 7.668980345335637\n",
      "900 7.681014444443841\n",
      "1000 7.692166189020467\n",
      "1100 7.682098646417587\n",
      "1200 7.713465964960999\n",
      "1300 7.719100154049636\n",
      "1400 7.7278203337330575\n",
      "1500 7.734686262335614\n",
      "1600 7.75893315721556\n",
      "1700 7.794222626869252\n",
      "1800 7.796769063685961\n"
     ]
    }
   ],
   "source": [
    "mcd_count = 0\n",
    "mcd = 0\n",
    "mcd_toolbox = Calculate_MCD(MCD_mode=\"dtw\")\n",
    "for i in d_list:\n",
    "    t_output_path = os.path.join(model_output_path, i)\n",
    "    t_gt_path = os.path.join(ground_truth_path, i)\n",
    "    w_list = os.listdir(t_output_path)\n",
    "    for wav_name in w_list:\n",
    "        if wav_name[-3:] !=\"wav\":\n",
    "            continue\n",
    "        mcd_value = mcd_toolbox.calculate_mcd(os.path.join(t_gt_path, wav_name), os.path.join(t_output_path, wav_name))\n",
    "        mcd += mcd_value\n",
    "        mcd_count += 1\n",
    "        if mcd_count % 100 == 0:\n",
    "            print(mcd_count, mcd/mcd_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ce4fbb8-a292-4d29-b830-3be608a57260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1834 7.790815976385192\n"
     ]
    }
   ],
   "source": [
    "print(mcd_count, mcd/mcd_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6821f85a-e313-4369-ae6c-77ef0039a165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
