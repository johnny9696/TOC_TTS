{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b46e5896-cda4-4d0a-8579-16f9e33b6aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyworld as pw\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "from pymcd.mcd import Calculate_MCD\n",
    "import audio as Audio\n",
    "# wav2vecSER Model\n",
    "from speechbrain.inference.interfaces import foreign_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b303642-afb2-4879-8721-7157a02a0fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d1653', 'd122', 'd2210', 'd1403', 'd79', 'd2077', 'd851', 'd2046', 'd1780', 'd520', 'd314', 'd1514', 'd2347', 'd1510', 'd1406', 'd213', 'd1248', 'd970', 'd1363', 'd295', 'd534', 'd2447', 'd115', 'd1542', 'd1774', 'd865', 'd1394', 'd1533', 'd236', 'd597', 'd1758', 'd1815', 'd1360', 'd1108', 'd2016', 'd794', 'd2400', 'd1075', 'd1927', 'd1856', 'd339', 'd2184', 'd283', 'd925', 'd1804', 'd954', 'd299', 'd1282', 'd1553', 'd2263', 'd1918', 'd1017', 'd87', 'd1180', 'd470', 'd2309', 'd872', 'd1700', 'd440', 'd1262', 'd1289', 'd1311', 'd2216', 'd2052', 'd1529', 'd2294', 'd47', 'd1434', 'd2511', 'd280', 'd1404', 'd279', 'd2459', 'd382', 'd1190', 'd2183', 'd718', 'd404', 'd2497', 'd777', 'd1233', 'd1632', 'd1222', 'd2515', 'd707', 'd172', 'd24', 'd40', 'd2', 'd1873', 'd2489', 'd2236', 'd1516', 'd2015', 'd168', 'd1937', 'd189', 'd222', 'd766', 'd800', 'd1645', 'd3', 'd466', 'd1905', 'd2524', 'd20', 'd855', 'd2382', 'd2131', 'd622', 'd1597', 'd2149', 'd2304', 'd1865', 'd1750', 'd2266', 'd1257', 'd1622', 'd1306', 'd1440', 'd1621', 'd1953', 'd521', 'd1368', 'd1531', 'd782', 'd2406', 'd2438', 'd218', 'd896', 'd1717', 'd114', 'd586', 'd250', 'd1817', 'd1889', 'd759', 'd2075', 'd1831', 'd1068', 'd1722', 'd1630', 'd905', 'd1944', 'd102', 'd1156', 'd1503', 'd472', 'd1671', 'd318', 'd1806', 'd856', 'd1414', 'd1102', 'd2349', 'd1391', 'd1485', 'd2145', 'd1947', 'd362', 'd1226', 'd2417', 'd1602', 'd1614', 'd2470', 'd247', 'd1848', 'd1850', 'd1764', 'd1924', 'd1625', 'd749', 'd54', 'd1577', 'd451', 'd1435', 'd1562', 'd221', 'd753', 'd1535', 'd1155', 'd1735', 'd962', 'd96', 'd2529', 'd119', 'd1193', 'd1922', 'd1884', 'd1471', 'd712', 'd2408', 'd557', 'd2514', 'd2273', 'd661', 'd1942', 'd1854', 'd465', 'd867']\n"
     ]
    }
   ],
   "source": [
    "ground_truth_path = \"/home/johnny9696/Desktop/DATA/dailytalk_resample/data\"\n",
    "#model_output_path = \"/mnt/hdd_storage/di_fit_tts_output/output/dailytalk\"\n",
    "#model_output_path = \"/mnt/hdd_storage/di_fit_tts_output/output/Fitted_v19_flowv2_MPE\"\n",
    "model_output_path = \"/mnt/hdd_storage/di_fit_tts_output/output/fs2\"\n",
    "sampling_rate = 22050\n",
    "hop_length = 256\n",
    "d_list = os.listdir(model_output_path)\n",
    "print(d_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d61602b-6afc-4b31-a39a-7ae7e4c166fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pitch(wav, sampling_rate = 22050, hop_length = 256):\n",
    "    pitch, t = pw.dio(\n",
    "        wav.astype(np.float64),\n",
    "        sampling_rate,\n",
    "        frame_period=hop_length / sampling_rate * 1000,\n",
    "    )\n",
    "    pitch = pw.stonemask(wav.astype(np.float64), pitch, t, sampling_rate)\n",
    "    return pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ee9ca55-d886-4df8-b84d-92d64286ee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_energy(wav):\n",
    "# Compute mel-scale spectrogram and energy\n",
    "        STFT = Audio.stft.TacotronSTFT(\n",
    "            1024,\n",
    "            256,\n",
    "            1024,\n",
    "            80,\n",
    "            22050,\n",
    "            0,\n",
    "            8000,\n",
    "        )\n",
    "        _, energy = Audio.tools.get_mel_from_wav(wav, STFT)\n",
    "        return energy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82871de6-ea07-4ea4-b189-cc94fac2edea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_93762/3240988841.py:24: RuntimeWarning: divide by zero encountered in log\n",
      "  gt_log = np.nan_to_num(np.log(gt_p))\n",
      "/tmp/ipykernel_93762/3240988841.py:25: RuntimeWarning: divide by zero encountered in log\n",
      "  gen_log = np.nan_to_num(np.log(gen_p))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.2622553493807052\n",
      "200 0.27224669272898266\n",
      "300 0.2723190405592484\n",
      "400 0.27082216030843465\n",
      "500 0.27317950056246637\n",
      "600 0.27314485067342226\n",
      "700 0.27155581829409065\n",
      "800 0.2713297779482404\n",
      "900 0.27378217248970205\n",
      "1000 0.27221664524959227\n",
      "1100 0.2774513412521834\n",
      "1200 0.2761424221721954\n",
      "1300 0.2754698341593281\n",
      "1400 0.2741265395185927\n",
      "1500 0.2733489440427654\n",
      "1600 0.27317135941765913\n",
      "1700 0.273377430935769\n",
      "1800 0.27194488623060187\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "wav_rmse = 0\n",
    "f0_rmse = 0\n",
    "for i in d_list:\n",
    "    t_output_path = os.path.join(model_output_path, i)\n",
    "    t_gt_path = os.path.join(ground_truth_path, i[1:])\n",
    "    w_list = os.listdir(t_output_path)\n",
    "    for wav_name in w_list:\n",
    "        if wav_name[-3:] !=\"wav\":\n",
    "            continue\n",
    "        gt_wav, sr = librosa.load(os.path.join(t_gt_path, wav_name))\n",
    "        gen_wav, sr = librosa.load(os.path.join(t_output_path, wav_name))\n",
    "        gt_p = get_pitch(gt_wav)\n",
    "        gen_p = get_pitch(gen_wav)\n",
    "        if len(gt_p) > len(gen_p):\n",
    "            gap = len(gt_p) - len(gen_p)\n",
    "            gt_p = gt_p[gap//2:-gap//2]\n",
    "            gen_p = gen_p[:len(gt_p)]\n",
    "        else:\n",
    "            gap = len(gen_p) - len(gt_p)\n",
    "            gen_p = gen_p[gap//2:-gap//2]\n",
    "            gt_p = gt_p[:len(gt_p)]\n",
    "        try:\n",
    "            gt_log = np.nan_to_num(np.log(gt_p))\n",
    "            gen_log = np.nan_to_num(np.log(gen_p))\n",
    "            error = abs(gt_log-gen_log)\n",
    "            non_inf_counter = 0\n",
    "            rmse = 0\n",
    "            for data in error:\n",
    "                if data != np.inf and data != -np.inf and data>= -10 and data <=10:\n",
    "                    non_inf_counter += 1\n",
    "                    rmse += data ** 2\n",
    "            rmse = np.sqrt(rmse/non_inf_counter)\n",
    "            f0_rmse += rmse\n",
    "            count += 1\n",
    "            if count%100 == 0:\n",
    "                print(count, f0_rmse/count)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37fb272f-bcd5-470b-9cba-87bc66f35168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2725826021264256\n"
     ]
    }
   ],
   "source": [
    "print(f0_rmse/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7884b0fc-50b6-4163-ac4b-51f466aba642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 2.236316002398535\n",
      "200 2.1933097876569785\n",
      "300 2.1842831585559135\n",
      "400 2.2203354207370136\n",
      "500 2.2135415732170785\n",
      "600 2.223354787546786\n",
      "700 2.22831623330988\n",
      "800 2.205511780173614\n",
      "900 2.195113002306916\n",
      "1000 2.1927496430898867\n",
      "1100 2.2007643248146787\n",
      "1200 2.217600462276618\n",
      "1300 2.221420117738284\n",
      "1400 2.218626925372667\n",
      "1500 2.2223912286237177\n",
      "1600 2.2403640266782157\n",
      "1700 2.235490814385781\n",
      "1800 2.228980665565161\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "e_rmse = 0\n",
    "for i in d_list:\n",
    "    t_output_path = os.path.join(model_output_path, i)\n",
    "    t_gt_path = os.path.join(ground_truth_path, i[1:])\n",
    "    w_list = os.listdir(t_output_path)\n",
    "    for wav_name in w_list:\n",
    "        if wav_name[-3:] !=\"wav\":\n",
    "            continue\n",
    "        gt_wav, sr = librosa.load(os.path.join(t_gt_path, wav_name))\n",
    "        gen_wav, sr = librosa.load(os.path.join(t_output_path, wav_name))\n",
    "        gt_p = get_energy(gt_wav)\n",
    "        gen_p = get_energy(gen_wav)\n",
    "        if len(gt_p) > len(gen_p):\n",
    "            gap = len(gt_p) - len(gen_p)\n",
    "            gt_p = gt_p[gap//2:-gap//2]\n",
    "            gen_p = gen_p[:len(gt_p)]\n",
    "        else:\n",
    "            gap = len(gen_p) - len(gt_p)\n",
    "            gen_p = gen_p[gap//2:-gap//2]\n",
    "            gt_p = gt_p[:len(gt_p)]\n",
    "        try:\n",
    "            gt_log = np.nan_to_num(np.log(gt_p))\n",
    "            gen_log = np.nan_to_num(np.log(gen_p))\n",
    "            error = abs(gt_log-gen_log)\n",
    "            non_inf_counter = 0\n",
    "            rmse = 0\n",
    "            for data in error:\n",
    "                if data != np.inf and data != -np.inf and data>= -10 and data <=10:\n",
    "                    non_inf_counter += 1\n",
    "                    rmse += data ** 2\n",
    "            rmse = np.sqrt(rmse/non_inf_counter)\n",
    "            e_rmse += rmse\n",
    "            count += 1\n",
    "            if count%100 == 0:\n",
    "                print(count, e_rmse/count)\n",
    "\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43da55ed-901a-4548-92ca-79f53cee7ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2236093952331655\n"
     ]
    }
   ],
   "source": [
    "print(e_rmse/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06bd8372-97c9-4439-a04d-1816630c15ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
     ]
    }
   ],
   "source": [
    "audio_embedder = foreign_class(source=\"speechbrain/emotion-recognition-wav2vec2-IEMOCAP\",\n",
    "                                       pymodule_file=\"custom_interface.py\", classname=\"CustomEncoderWav2vec2Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ecc979f-9b3c-497a-a651-6b726640afd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.8347542335093021\n",
      "200 0.860781531855464\n",
      "300 0.8707387032608191\n",
      "400 0.8580506410822273\n",
      "500 0.8438284749537707\n",
      "600 0.8516770665720105\n",
      "700 0.8474428770691156\n",
      "800 0.8441312044765801\n",
      "900 0.8468414485537343\n",
      "1000 0.8549331518188119\n",
      "1100 0.8564677710627968\n",
      "1200 0.8577232097027202\n",
      "1300 0.8560013628521791\n",
      "1400 0.8576178757154516\n",
      "1500 0.8574154142091671\n",
      "1600 0.8542872145446018\n",
      "1700 0.8575794335454703\n",
      "1800 0.8576563020423055\n"
     ]
    }
   ],
   "source": [
    "w_count = 0\n",
    "wav_rmse = 0\n",
    "for i in d_list:\n",
    "    t_output_path = os.path.join(model_output_path, i)\n",
    "    t_gt_path = os.path.join(ground_truth_path, i[1:])\n",
    "    w_list = os.listdir(t_output_path)\n",
    "    for wav_name in w_list:\n",
    "        if wav_name[-3:] !=\"wav\":\n",
    "            continue\n",
    "        gt_wav, sr = librosa.load(os.path.join(t_gt_path, wav_name))\n",
    "        gen_wav, sr = librosa.load(os.path.join(t_output_path, wav_name))\n",
    "        gt_wav_e = torch.tensor(gt_wav)\n",
    "        gt_wav_emb = audio_embedder.encode_batch(gt_wav_e)\n",
    "        gt_wav_emb = np.array(gt_wav_emb.squeeze(0))\n",
    "        gen_wav_e = torch.tensor(gen_wav)\n",
    "        gen_wav_emb = audio_embedder.encode_batch(gen_wav_e)\n",
    "        gen_wav_emb = np.array(gen_wav_emb.squeeze(0))\n",
    "        error = abs(gt_wav_emb - gen_wav_emb)\n",
    "        rmse = np.sqrt(np.mean(error**2))\n",
    "        wav_rmse += rmse\n",
    "        w_count += 1\n",
    "        if w_count%100 == 0:\n",
    "            print(w_count, wav_rmse/w_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6a316af-1703-457c-915c-1a4d476e5ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8584494442032039\n"
     ]
    }
   ],
   "source": [
    "print(wav_rmse/w_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6d08dd5-fd74-49b4-af10-6db010771de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 8.35187807190436\n",
      "200 8.390435571753672\n",
      "300 8.423236111250777\n",
      "400 8.29415496798119\n",
      "500 8.300448298817582\n",
      "600 8.329507913179528\n",
      "700 8.301066396498667\n",
      "800 8.331559100039943\n",
      "900 8.342863679419859\n",
      "1000 8.31056878174379\n",
      "1100 8.357093828898023\n",
      "1200 8.423498355210173\n",
      "1300 8.421160599658865\n",
      "1400 8.443242400567577\n",
      "1500 8.461479024561152\n",
      "1600 8.46661786018398\n",
      "1700 8.456371525342329\n",
      "1800 8.4184887711868\n"
     ]
    }
   ],
   "source": [
    "mcd_count = 0\n",
    "mcd = 0\n",
    "mcd_toolbox = Calculate_MCD(MCD_mode=\"dtw\")\n",
    "for i in d_list:\n",
    "    t_output_path = os.path.join(model_output_path, i)\n",
    "    t_gt_path = os.path.join(ground_truth_path, i[1:])\n",
    "    w_list = os.listdir(t_output_path)\n",
    "    for wav_name in w_list:\n",
    "        if wav_name[-3:] !=\"wav\":\n",
    "            continue\n",
    "        mcd_value = mcd_toolbox.calculate_mcd(os.path.join(t_gt_path, wav_name), os.path.join(t_output_path, wav_name))\n",
    "        mcd += mcd_value\n",
    "        mcd_count += 1\n",
    "        if mcd_count % 100 == 0:\n",
    "            print(mcd_count, mcd/mcd_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ce4fbb8-a292-4d29-b830-3be608a57260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1834 8.416269685855791\n"
     ]
    }
   ],
   "source": [
    "print(mcd_count, mcd/mcd_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6821f85a-e313-4369-ae6c-77ef0039a165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
