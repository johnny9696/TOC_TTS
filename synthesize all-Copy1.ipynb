{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b87ef77e-4eb5-4eaf-bb66-28c4b8e377c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from model import Fitted_DT\n",
    "from utils.model import get_model, get_vocoder, get_param_num\n",
    "from utils.tools import to_device_eval\n",
    "from dataset import Dialogue_dataset_eval\n",
    "from scipy.io import wavfile\n",
    "from utils.model import vocoder_infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e26a1d6-7f61-4795-81ad-1c11b3379a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2331aad0-49e2-4710-86ad-763a268389cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name = \"Fitted_v19_flowv2_length4\"\n",
    "preprocess_path = \"./config/Fitted_DT/preprocess.yaml\"\n",
    "model_path = \"./config/Fitted_DT/model.yaml\"\n",
    "train_path = \"./config/Fitted_DT/train.yaml\"\n",
    "preprocess_config = yaml.load(open(preprocess_path, \"r\"), Loader=yaml.FullLoader)\n",
    "model_config = yaml.load(open(model_path, \"r\"), Loader=yaml.FullLoader)\n",
    "train_config = yaml.load(open(train_path, \"r\"), Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8244966e-5597-494a-9de6-c63b6a427f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup = train_config[\"optimizer\"][\"warm_up_step\"]\n",
    "model = Fitted_DT(preprocess_config, model_config, warmup*2)\n",
    "model1 = Fitted_DT(preprocess_config, model_config, warmup*2)\n",
    "step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cdf8f37-a097-4fdd-92bb-ee2ceb7fbcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "                        {\n",
    "                            \"model\": model.state_dict(),\n",
    "                        },\n",
    "                        os.path.join(\n",
    "                            train_config[\"path\"][\"ckpt_path\"],\n",
    "                            \"{}.pth.tar\".format(step),\n",
    "                        ),\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b81af86-d06c-451a-95f1-4276baf12728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_path = os.path.join(\n",
    "    train_config[\"path\"][\"ckpt_path\"],\n",
    "    \"{}.pth.tar\".format(1),\n",
    ")\n",
    "ckpt = torch.load(ckpt_path)\n",
    "model1.load_state_dict(ckpt[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1bb0a01-878d-445d-ad23-be3ce5f29df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_model_param_diff(model1, model2):\n",
    "    \"\"\"\n",
    "    두 모델의 파라미터 차이를 계산합니다.\n",
    "    :param model1: 첫 번째 모델\n",
    "    :param model2: 두 번째 모델\n",
    "    :return: 두 모델의 파라미터 차이\n",
    "    \"\"\"\n",
    "    # 두 모델의 파라미터를 가져옵니다.\n",
    "    params1 = dict(model1.named_parameters())\n",
    "    params2 = dict(model2.named_parameters())\n",
    "\n",
    "    # 파라미터 차이를 저장할 딕셔너리\n",
    "    param_diff = {}\n",
    "\n",
    "    # 모델 1의 파라미터가 모델 2에 존재하는지 확인하고 차이를 계산\n",
    "    for name, param1 in params1.items():\n",
    "        if name in params2:\n",
    "            param2 = params2[name]\n",
    "            # 파라미터 차이 계산 (절대 차이 또는 상대 차이)\n",
    "            diff = torch.abs(param1.data - param2.data)\n",
    "            print(name, torch.sum(diff))\n",
    "            param_diff[name] = diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0551e1b6-9414-495a-af49-888fd1508af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position_enc tensor(0.)\n",
      "encoder.position_enc tensor(0.)\n",
      "encoder.src_word_emb.weight tensor(0.)\n",
      "encoder.layer_stack.0.slf_attn.w_qs.weight tensor(0.)\n",
      "encoder.layer_stack.0.slf_attn.w_qs.bias tensor(0.)\n",
      "encoder.layer_stack.0.slf_attn.w_ks.weight tensor(0.)\n",
      "encoder.layer_stack.0.slf_attn.w_ks.bias tensor(0.)\n",
      "encoder.layer_stack.0.slf_attn.w_vs.weight tensor(0.)\n",
      "encoder.layer_stack.0.slf_attn.w_vs.bias tensor(0.)\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.weight tensor(0.)\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.bias tensor(0.)\n",
      "encoder.layer_stack.0.slf_attn.fc.weight tensor(0.)\n",
      "encoder.layer_stack.0.slf_attn.fc.bias tensor(0.)\n",
      "encoder.layer_stack.0.pos_ffn.w_1.weight tensor(0.)\n",
      "encoder.layer_stack.0.pos_ffn.w_1.bias tensor(0.)\n",
      "encoder.layer_stack.0.pos_ffn.w_2.weight tensor(0.)\n",
      "encoder.layer_stack.0.pos_ffn.w_2.bias tensor(0.)\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.weight tensor(0.)\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.bias tensor(0.)\n",
      "encoder.layer_stack.1.slf_attn.w_qs.weight tensor(0.)\n",
      "encoder.layer_stack.1.slf_attn.w_qs.bias tensor(0.)\n",
      "encoder.layer_stack.1.slf_attn.w_ks.weight tensor(0.)\n",
      "encoder.layer_stack.1.slf_attn.w_ks.bias tensor(0.)\n",
      "encoder.layer_stack.1.slf_attn.w_vs.weight tensor(0.)\n",
      "encoder.layer_stack.1.slf_attn.w_vs.bias tensor(0.)\n",
      "encoder.layer_stack.1.slf_attn.layer_norm.weight tensor(0.)\n",
      "encoder.layer_stack.1.slf_attn.layer_norm.bias tensor(0.)\n",
      "encoder.layer_stack.1.slf_attn.fc.weight tensor(0.)\n",
      "encoder.layer_stack.1.slf_attn.fc.bias tensor(0.)\n",
      "encoder.layer_stack.1.pos_ffn.w_1.weight tensor(0.)\n",
      "encoder.layer_stack.1.pos_ffn.w_1.bias tensor(0.)\n",
      "encoder.layer_stack.1.pos_ffn.w_2.weight tensor(0.)\n",
      "encoder.layer_stack.1.pos_ffn.w_2.bias tensor(0.)\n",
      "encoder.layer_stack.1.pos_ffn.layer_norm.weight tensor(0.)\n",
      "encoder.layer_stack.1.pos_ffn.layer_norm.bias tensor(0.)\n",
      "encoder.layer_stack.2.slf_attn.w_qs.weight tensor(0.)\n",
      "encoder.layer_stack.2.slf_attn.w_qs.bias tensor(0.)\n",
      "encoder.layer_stack.2.slf_attn.w_ks.weight tensor(0.)\n",
      "encoder.layer_stack.2.slf_attn.w_ks.bias tensor(0.)\n",
      "encoder.layer_stack.2.slf_attn.w_vs.weight tensor(0.)\n",
      "encoder.layer_stack.2.slf_attn.w_vs.bias tensor(0.)\n",
      "encoder.layer_stack.2.slf_attn.layer_norm.weight tensor(0.)\n",
      "encoder.layer_stack.2.slf_attn.layer_norm.bias tensor(0.)\n",
      "encoder.layer_stack.2.slf_attn.fc.weight tensor(0.)\n",
      "encoder.layer_stack.2.slf_attn.fc.bias tensor(0.)\n",
      "encoder.layer_stack.2.pos_ffn.w_1.weight tensor(0.)\n",
      "encoder.layer_stack.2.pos_ffn.w_1.bias tensor(0.)\n",
      "encoder.layer_stack.2.pos_ffn.w_2.weight tensor(0.)\n",
      "encoder.layer_stack.2.pos_ffn.w_2.bias tensor(0.)\n",
      "encoder.layer_stack.2.pos_ffn.layer_norm.weight tensor(0.)\n",
      "encoder.layer_stack.2.pos_ffn.layer_norm.bias tensor(0.)\n",
      "encoder.layer_stack.3.slf_attn.w_qs.weight tensor(0.)\n",
      "encoder.layer_stack.3.slf_attn.w_qs.bias tensor(0.)\n",
      "encoder.layer_stack.3.slf_attn.w_ks.weight tensor(0.)\n",
      "encoder.layer_stack.3.slf_attn.w_ks.bias tensor(0.)\n",
      "encoder.layer_stack.3.slf_attn.w_vs.weight tensor(0.)\n",
      "encoder.layer_stack.3.slf_attn.w_vs.bias tensor(0.)\n",
      "encoder.layer_stack.3.slf_attn.layer_norm.weight tensor(0.)\n",
      "encoder.layer_stack.3.slf_attn.layer_norm.bias tensor(0.)\n",
      "encoder.layer_stack.3.slf_attn.fc.weight tensor(0.)\n",
      "encoder.layer_stack.3.slf_attn.fc.bias tensor(0.)\n",
      "encoder.layer_stack.3.pos_ffn.w_1.weight tensor(0.)\n",
      "encoder.layer_stack.3.pos_ffn.w_1.bias tensor(0.)\n",
      "encoder.layer_stack.3.pos_ffn.w_2.weight tensor(0.)\n",
      "encoder.layer_stack.3.pos_ffn.w_2.bias tensor(0.)\n",
      "encoder.layer_stack.3.pos_ffn.layer_norm.weight tensor(0.)\n",
      "encoder.layer_stack.3.pos_ffn.layer_norm.bias tensor(0.)\n",
      "variance_adaptor.pitch_bins tensor(0.)\n",
      "variance_adaptor.energy_bins tensor(0.)\n",
      "variance_adaptor.duration_predictor.conv_layer.conv1d_1.conv.weight tensor(0.)\n",
      "variance_adaptor.duration_predictor.conv_layer.conv1d_1.conv.bias tensor(0.)\n",
      "variance_adaptor.duration_predictor.conv_layer.layer_norm_1.weight tensor(0.)\n",
      "variance_adaptor.duration_predictor.conv_layer.layer_norm_1.bias tensor(0.)\n",
      "variance_adaptor.duration_predictor.conv_layer.conv1d_2.conv.weight tensor(0.)\n",
      "variance_adaptor.duration_predictor.conv_layer.conv1d_2.conv.bias tensor(0.)\n",
      "variance_adaptor.duration_predictor.conv_layer.layer_norm_2.weight tensor(0.)\n",
      "variance_adaptor.duration_predictor.conv_layer.layer_norm_2.bias tensor(0.)\n",
      "variance_adaptor.duration_predictor.linear_layer.weight tensor(0.)\n",
      "variance_adaptor.duration_predictor.linear_layer.bias tensor(0.)\n",
      "variance_adaptor.pitch_predictor.conv_layer.conv1d_1.conv.weight tensor(0.)\n",
      "variance_adaptor.pitch_predictor.conv_layer.conv1d_1.conv.bias tensor(0.)\n",
      "variance_adaptor.pitch_predictor.conv_layer.layer_norm_1.weight tensor(0.)\n",
      "variance_adaptor.pitch_predictor.conv_layer.layer_norm_1.bias tensor(0.)\n",
      "variance_adaptor.pitch_predictor.conv_layer.conv1d_2.conv.weight tensor(0.)\n",
      "variance_adaptor.pitch_predictor.conv_layer.conv1d_2.conv.bias tensor(0.)\n",
      "variance_adaptor.pitch_predictor.conv_layer.layer_norm_2.weight tensor(0.)\n",
      "variance_adaptor.pitch_predictor.conv_layer.layer_norm_2.bias tensor(0.)\n",
      "variance_adaptor.pitch_predictor.linear_layer.weight tensor(0.)\n",
      "variance_adaptor.pitch_predictor.linear_layer.bias tensor(0.)\n",
      "variance_adaptor.energy_predictor.conv_layer.conv1d_1.conv.weight tensor(0.)\n",
      "variance_adaptor.energy_predictor.conv_layer.conv1d_1.conv.bias tensor(0.)\n",
      "variance_adaptor.energy_predictor.conv_layer.layer_norm_1.weight tensor(0.)\n",
      "variance_adaptor.energy_predictor.conv_layer.layer_norm_1.bias tensor(0.)\n",
      "variance_adaptor.energy_predictor.conv_layer.conv1d_2.conv.weight tensor(0.)\n",
      "variance_adaptor.energy_predictor.conv_layer.conv1d_2.conv.bias tensor(0.)\n",
      "variance_adaptor.energy_predictor.conv_layer.layer_norm_2.weight tensor(0.)\n",
      "variance_adaptor.energy_predictor.conv_layer.layer_norm_2.bias tensor(0.)\n",
      "variance_adaptor.energy_predictor.linear_layer.weight tensor(0.)\n",
      "variance_adaptor.energy_predictor.linear_layer.bias tensor(0.)\n",
      "variance_adaptor.pitch_embedding.weight tensor(0.)\n",
      "variance_adaptor.energy_embedding.weight tensor(0.)\n",
      "history_context.position_enc tensor(0.)\n",
      "history_context.bert_linear.weight tensor(0.)\n",
      "history_context.bert_linear.bias tensor(0.)\n",
      "history_context.sbert_linear.weight tensor(0.)\n",
      "history_context.sbert_linear.bias tensor(0.)\n",
      "history_context.speaker_linear.weight tensor(0.)\n",
      "history_context.speaker_linear.bias tensor(0.)\n",
      "history_context.context_predictor.0.slf_attention.w_qs.weight tensor(0.)\n",
      "history_context.context_predictor.0.slf_attention.w_qs.bias tensor(0.)\n",
      "history_context.context_predictor.0.slf_attention.w_ks.weight tensor(0.)\n",
      "history_context.context_predictor.0.slf_attention.w_ks.bias tensor(0.)\n",
      "history_context.context_predictor.0.slf_attention.w_vs.weight tensor(0.)\n",
      "history_context.context_predictor.0.slf_attention.w_vs.bias tensor(0.)\n",
      "history_context.context_predictor.0.slf_attention.layer_norm.weight tensor(0.)\n",
      "history_context.context_predictor.0.slf_attention.layer_norm.bias tensor(0.)\n",
      "history_context.context_predictor.0.slf_attention.fc.weight tensor(0.)\n",
      "history_context.context_predictor.0.slf_attention.fc.bias tensor(0.)\n",
      "history_context.context_predictor.0.layernorm1.gamma tensor(0.)\n",
      "history_context.context_predictor.0.layernorm1.bias tensor(0.)\n",
      "history_context.context_predictor.0.linear.0.weight tensor(0.)\n",
      "history_context.context_predictor.0.linear.0.bias tensor(0.)\n",
      "history_context.context_predictor.0.layernorm2.gamma tensor(0.)\n",
      "history_context.context_predictor.0.layernorm2.bias tensor(0.)\n",
      "history_context.context_predictor.1.slf_attention.w_qs.weight tensor(0.)\n",
      "history_context.context_predictor.1.slf_attention.w_qs.bias tensor(0.)\n",
      "history_context.context_predictor.1.slf_attention.w_ks.weight tensor(0.)\n",
      "history_context.context_predictor.1.slf_attention.w_ks.bias tensor(0.)\n",
      "history_context.context_predictor.1.slf_attention.w_vs.weight tensor(0.)\n",
      "history_context.context_predictor.1.slf_attention.w_vs.bias tensor(0.)\n",
      "history_context.context_predictor.1.slf_attention.layer_norm.weight tensor(0.)\n",
      "history_context.context_predictor.1.slf_attention.layer_norm.bias tensor(0.)\n",
      "history_context.context_predictor.1.slf_attention.fc.weight tensor(0.)\n",
      "history_context.context_predictor.1.slf_attention.fc.bias tensor(0.)\n",
      "history_context.context_predictor.1.layernorm1.gamma tensor(0.)\n",
      "history_context.context_predictor.1.layernorm1.bias tensor(0.)\n",
      "history_context.context_predictor.1.linear.0.weight tensor(0.)\n",
      "history_context.context_predictor.1.linear.0.bias tensor(0.)\n",
      "history_context.context_predictor.1.layernorm2.gamma tensor(0.)\n",
      "history_context.context_predictor.1.layernorm2.bias tensor(0.)\n",
      "history_context.context_predictor.2.slf_attention.w_qs.weight tensor(0.)\n",
      "history_context.context_predictor.2.slf_attention.w_qs.bias tensor(0.)\n",
      "history_context.context_predictor.2.slf_attention.w_ks.weight tensor(0.)\n",
      "history_context.context_predictor.2.slf_attention.w_ks.bias tensor(0.)\n",
      "history_context.context_predictor.2.slf_attention.w_vs.weight tensor(0.)\n",
      "history_context.context_predictor.2.slf_attention.w_vs.bias tensor(0.)\n",
      "history_context.context_predictor.2.slf_attention.layer_norm.weight tensor(0.)\n",
      "history_context.context_predictor.2.slf_attention.layer_norm.bias tensor(0.)\n",
      "history_context.context_predictor.2.slf_attention.fc.weight tensor(0.)\n",
      "history_context.context_predictor.2.slf_attention.fc.bias tensor(0.)\n",
      "history_context.context_predictor.2.layernorm1.gamma tensor(0.)\n",
      "history_context.context_predictor.2.layernorm1.bias tensor(0.)\n",
      "history_context.context_predictor.2.linear.0.weight tensor(0.)\n",
      "history_context.context_predictor.2.linear.0.bias tensor(0.)\n",
      "history_context.context_predictor.2.layernorm2.gamma tensor(0.)\n",
      "history_context.context_predictor.2.layernorm2.bias tensor(0.)\n",
      "history_context.context_predictor.3.slf_attention.w_qs.weight tensor(0.)\n",
      "history_context.context_predictor.3.slf_attention.w_qs.bias tensor(0.)\n",
      "history_context.context_predictor.3.slf_attention.w_ks.weight tensor(0.)\n",
      "history_context.context_predictor.3.slf_attention.w_ks.bias tensor(0.)\n",
      "history_context.context_predictor.3.slf_attention.w_vs.weight tensor(0.)\n",
      "history_context.context_predictor.3.slf_attention.w_vs.bias tensor(0.)\n",
      "history_context.context_predictor.3.slf_attention.layer_norm.weight tensor(0.)\n",
      "history_context.context_predictor.3.slf_attention.layer_norm.bias tensor(0.)\n",
      "history_context.context_predictor.3.slf_attention.fc.weight tensor(0.)\n",
      "history_context.context_predictor.3.slf_attention.fc.bias tensor(0.)\n",
      "history_context.context_predictor.3.layernorm1.gamma tensor(0.)\n",
      "history_context.context_predictor.3.layernorm1.bias tensor(0.)\n",
      "history_context.context_predictor.3.linear.0.weight tensor(0.)\n",
      "history_context.context_predictor.3.linear.0.bias tensor(0.)\n",
      "history_context.context_predictor.3.layernorm2.gamma tensor(0.)\n",
      "history_context.context_predictor.3.layernorm2.bias tensor(0.)\n",
      "history_context.context_predictor.4.slf_attention.w_qs.weight tensor(0.)\n",
      "history_context.context_predictor.4.slf_attention.w_qs.bias tensor(0.)\n",
      "history_context.context_predictor.4.slf_attention.w_ks.weight tensor(0.)\n",
      "history_context.context_predictor.4.slf_attention.w_ks.bias tensor(0.)\n",
      "history_context.context_predictor.4.slf_attention.w_vs.weight tensor(0.)\n",
      "history_context.context_predictor.4.slf_attention.w_vs.bias tensor(0.)\n",
      "history_context.context_predictor.4.slf_attention.layer_norm.weight tensor(0.)\n",
      "history_context.context_predictor.4.slf_attention.layer_norm.bias tensor(0.)\n",
      "history_context.context_predictor.4.slf_attention.fc.weight tensor(0.)\n",
      "history_context.context_predictor.4.slf_attention.fc.bias tensor(0.)\n",
      "history_context.context_predictor.4.layernorm1.gamma tensor(0.)\n",
      "history_context.context_predictor.4.layernorm1.bias tensor(0.)\n",
      "history_context.context_predictor.4.linear.0.weight tensor(0.)\n",
      "history_context.context_predictor.4.linear.0.bias tensor(0.)\n",
      "history_context.context_predictor.4.layernorm2.gamma tensor(0.)\n",
      "history_context.context_predictor.4.layernorm2.bias tensor(0.)\n",
      "history_context.emotion_predictor.0.slf_attn.w_qs.weight tensor(0.)\n",
      "history_context.emotion_predictor.0.slf_attn.w_qs.bias tensor(0.)\n",
      "history_context.emotion_predictor.0.slf_attn.w_ks.weight tensor(0.)\n",
      "history_context.emotion_predictor.0.slf_attn.w_ks.bias tensor(0.)\n",
      "history_context.emotion_predictor.0.slf_attn.w_vs.weight tensor(0.)\n",
      "history_context.emotion_predictor.0.slf_attn.w_vs.bias tensor(0.)\n",
      "history_context.emotion_predictor.0.slf_attn.layer_norm.weight tensor(0.)\n",
      "history_context.emotion_predictor.0.slf_attn.layer_norm.bias tensor(0.)\n",
      "history_context.emotion_predictor.0.slf_attn.fc.weight tensor(0.)\n",
      "history_context.emotion_predictor.0.slf_attn.fc.bias tensor(0.)\n",
      "history_context.emotion_predictor.0.layernorm1.gamma tensor(0.)\n",
      "history_context.emotion_predictor.0.layernorm1.bias tensor(0.)\n",
      "history_context.emotion_predictor.0.linear.0.weight tensor(0.)\n",
      "history_context.emotion_predictor.0.linear.0.bias tensor(0.)\n",
      "history_context.emotion_predictor.0.linear.2.weight tensor(0.)\n",
      "history_context.emotion_predictor.0.linear.2.bias tensor(0.)\n",
      "history_context.emotion_predictor.0.layernorm2.gamma tensor(0.)\n",
      "history_context.emotion_predictor.0.layernorm2.bias tensor(0.)\n",
      "history_context.emotion_predictor.0.out_linear.weight tensor(0.)\n",
      "history_context.emotion_predictor.0.out_linear.bias tensor(0.)\n",
      "history_context.emotion_predictor.1.slf_attn.w_qs.weight tensor(0.)\n",
      "history_context.emotion_predictor.1.slf_attn.w_qs.bias tensor(0.)\n",
      "history_context.emotion_predictor.1.slf_attn.w_ks.weight tensor(0.)\n",
      "history_context.emotion_predictor.1.slf_attn.w_ks.bias tensor(0.)\n",
      "history_context.emotion_predictor.1.slf_attn.w_vs.weight tensor(0.)\n",
      "history_context.emotion_predictor.1.slf_attn.w_vs.bias tensor(0.)\n",
      "history_context.emotion_predictor.1.slf_attn.layer_norm.weight tensor(0.)\n",
      "history_context.emotion_predictor.1.slf_attn.layer_norm.bias tensor(0.)\n",
      "history_context.emotion_predictor.1.slf_attn.fc.weight tensor(0.)\n",
      "history_context.emotion_predictor.1.slf_attn.fc.bias tensor(0.)\n",
      "history_context.emotion_predictor.1.layernorm1.gamma tensor(0.)\n",
      "history_context.emotion_predictor.1.layernorm1.bias tensor(0.)\n",
      "history_context.emotion_predictor.1.linear.0.weight tensor(0.)\n",
      "history_context.emotion_predictor.1.linear.0.bias tensor(0.)\n",
      "history_context.emotion_predictor.1.linear.2.weight tensor(0.)\n",
      "history_context.emotion_predictor.1.linear.2.bias tensor(0.)\n",
      "history_context.emotion_predictor.1.layernorm2.gamma tensor(0.)\n",
      "history_context.emotion_predictor.1.layernorm2.bias tensor(0.)\n",
      "history_context.emotion_predictor.1.out_linear.weight tensor(0.)\n",
      "history_context.emotion_predictor.1.out_linear.bias tensor(0.)\n",
      "history_context.emotion_predictor.2.slf_attn.w_qs.weight tensor(0.)\n",
      "history_context.emotion_predictor.2.slf_attn.w_qs.bias tensor(0.)\n",
      "history_context.emotion_predictor.2.slf_attn.w_ks.weight tensor(0.)\n",
      "history_context.emotion_predictor.2.slf_attn.w_ks.bias tensor(0.)\n",
      "history_context.emotion_predictor.2.slf_attn.w_vs.weight tensor(0.)\n",
      "history_context.emotion_predictor.2.slf_attn.w_vs.bias tensor(0.)\n",
      "history_context.emotion_predictor.2.slf_attn.layer_norm.weight tensor(0.)\n",
      "history_context.emotion_predictor.2.slf_attn.layer_norm.bias tensor(0.)\n",
      "history_context.emotion_predictor.2.slf_attn.fc.weight tensor(0.)\n",
      "history_context.emotion_predictor.2.slf_attn.fc.bias tensor(0.)\n",
      "history_context.emotion_predictor.2.layernorm1.gamma tensor(0.)\n",
      "history_context.emotion_predictor.2.layernorm1.bias tensor(0.)\n",
      "history_context.emotion_predictor.2.linear.0.weight tensor(0.)\n",
      "history_context.emotion_predictor.2.linear.0.bias tensor(0.)\n",
      "history_context.emotion_predictor.2.linear.2.weight tensor(0.)\n",
      "history_context.emotion_predictor.2.linear.2.bias tensor(0.)\n",
      "history_context.emotion_predictor.2.layernorm2.gamma tensor(0.)\n",
      "history_context.emotion_predictor.2.layernorm2.bias tensor(0.)\n",
      "history_context.emotion_predictor.2.out_linear.weight tensor(0.)\n",
      "history_context.emotion_predictor.2.out_linear.bias tensor(0.)\n",
      "history_context.emotion_predictor.3.slf_attn.w_qs.weight tensor(0.)\n",
      "history_context.emotion_predictor.3.slf_attn.w_qs.bias tensor(0.)\n",
      "history_context.emotion_predictor.3.slf_attn.w_ks.weight tensor(0.)\n",
      "history_context.emotion_predictor.3.slf_attn.w_ks.bias tensor(0.)\n",
      "history_context.emotion_predictor.3.slf_attn.w_vs.weight tensor(0.)\n",
      "history_context.emotion_predictor.3.slf_attn.w_vs.bias tensor(0.)\n",
      "history_context.emotion_predictor.3.slf_attn.layer_norm.weight tensor(0.)\n",
      "history_context.emotion_predictor.3.slf_attn.layer_norm.bias tensor(0.)\n",
      "history_context.emotion_predictor.3.slf_attn.fc.weight tensor(0.)\n",
      "history_context.emotion_predictor.3.slf_attn.fc.bias tensor(0.)\n",
      "history_context.emotion_predictor.3.layernorm1.gamma tensor(0.)\n",
      "history_context.emotion_predictor.3.layernorm1.bias tensor(0.)\n",
      "history_context.emotion_predictor.3.linear.0.weight tensor(0.)\n",
      "history_context.emotion_predictor.3.linear.0.bias tensor(0.)\n",
      "history_context.emotion_predictor.3.linear.2.weight tensor(0.)\n",
      "history_context.emotion_predictor.3.linear.2.bias tensor(0.)\n",
      "history_context.emotion_predictor.3.layernorm2.gamma tensor(0.)\n",
      "history_context.emotion_predictor.3.layernorm2.bias tensor(0.)\n",
      "history_context.emotion_predictor.3.out_linear.weight tensor(0.)\n",
      "history_context.emotion_predictor.3.out_linear.bias tensor(0.)\n",
      "history_context.emotion_predictor.4.slf_attn.w_qs.weight tensor(0.)\n",
      "history_context.emotion_predictor.4.slf_attn.w_qs.bias tensor(0.)\n",
      "history_context.emotion_predictor.4.slf_attn.w_ks.weight tensor(0.)\n",
      "history_context.emotion_predictor.4.slf_attn.w_ks.bias tensor(0.)\n",
      "history_context.emotion_predictor.4.slf_attn.w_vs.weight tensor(0.)\n",
      "history_context.emotion_predictor.4.slf_attn.w_vs.bias tensor(0.)\n",
      "history_context.emotion_predictor.4.slf_attn.layer_norm.weight tensor(0.)\n",
      "history_context.emotion_predictor.4.slf_attn.layer_norm.bias tensor(0.)\n",
      "history_context.emotion_predictor.4.slf_attn.fc.weight tensor(0.)\n",
      "history_context.emotion_predictor.4.slf_attn.fc.bias tensor(0.)\n",
      "history_context.emotion_predictor.4.layernorm1.gamma tensor(0.)\n",
      "history_context.emotion_predictor.4.layernorm1.bias tensor(0.)\n",
      "history_context.emotion_predictor.4.linear.0.weight tensor(0.)\n",
      "history_context.emotion_predictor.4.linear.0.bias tensor(0.)\n",
      "history_context.emotion_predictor.4.linear.2.weight tensor(0.)\n",
      "history_context.emotion_predictor.4.linear.2.bias tensor(0.)\n",
      "history_context.emotion_predictor.4.layernorm2.gamma tensor(0.)\n",
      "history_context.emotion_predictor.4.layernorm2.bias tensor(0.)\n",
      "history_context.emotion_predictor.4.out_linear.weight tensor(0.)\n",
      "history_context.emotion_predictor.4.out_linear.bias tensor(0.)\n",
      "history_context.token_duration.conv_layer.conv1d_1.conv.weight tensor(0.)\n",
      "history_context.token_duration.conv_layer.conv1d_1.conv.bias tensor(0.)\n",
      "history_context.token_duration.conv_layer.layer_norm_1.weight tensor(0.)\n",
      "history_context.token_duration.conv_layer.layer_norm_1.bias tensor(0.)\n",
      "history_context.token_duration.conv_layer.conv1d_2.conv.weight tensor(0.)\n",
      "history_context.token_duration.conv_layer.conv1d_2.conv.bias tensor(0.)\n",
      "history_context.token_duration.conv_layer.layer_norm_2.weight tensor(0.)\n",
      "history_context.token_duration.conv_layer.layer_norm_2.bias tensor(0.)\n",
      "history_context.token_duration.linear_layer.weight tensor(0.)\n",
      "history_context.token_duration.linear_layer.bias tensor(0.)\n",
      "history_context.mixer.conv1d_0.0.weight tensor(0.)\n",
      "history_context.mixer.conv1d_0.0.bias tensor(0.)\n",
      "history_context.mixer.conv1d_0.3.weight tensor(0.)\n",
      "history_context.mixer.conv1d_0.3.bias tensor(0.)\n",
      "history_context.mixer.conv1d_1.0.weight tensor(0.)\n",
      "history_context.mixer.conv1d_1.0.bias tensor(0.)\n",
      "history_context.mixer.conv1d_1.3.weight tensor(0.)\n",
      "history_context.mixer.conv1d_1.3.bias tensor(0.)\n",
      "history_context.mixer.out_linear.weight tensor(0.)\n",
      "history_context.mixer.out_linear.bias tensor(0.)\n",
      "history_context.cross.w_qs.weight tensor(0.)\n",
      "history_context.cross.w_qs.bias tensor(0.)\n",
      "history_context.cross.w_ks.weight tensor(0.)\n",
      "history_context.cross.w_ks.bias tensor(0.)\n",
      "history_context.cross.w_vs.weight tensor(0.)\n",
      "history_context.cross.w_vs.bias tensor(0.)\n",
      "history_context.cross.layer_norm.weight tensor(0.)\n",
      "history_context.cross.layer_norm.bias tensor(0.)\n",
      "history_context.cross.fc.weight tensor(0.)\n",
      "history_context.cross.fc.bias tensor(0.)\n",
      "mel_emb.conv2d_1.0.weight tensor(0.)\n",
      "mel_emb.conv2d_1.0.bias tensor(0.)\n",
      "mel_emb.conv2d_1.1.weight tensor(0.)\n",
      "mel_emb.conv2d_1.1.bias tensor(0.)\n",
      "mel_emb.conv2d_2.0.weight tensor(0.)\n",
      "mel_emb.conv2d_2.0.bias tensor(0.)\n",
      "mel_emb.conv2d_2.1.weight tensor(0.)\n",
      "mel_emb.conv2d_2.1.bias tensor(0.)\n",
      "mel_emb.mean_gru.weight_ih_l0 tensor(0.)\n",
      "mel_emb.mean_gru.weight_hh_l0 tensor(0.)\n",
      "mel_emb.mean_gru.bias_ih_l0 tensor(0.)\n",
      "mel_emb.mean_gru.bias_hh_l0 tensor(0.)\n",
      "mel_emb.conv1d_1.0.weight tensor(0.)\n",
      "mel_emb.conv1d_1.0.bias tensor(0.)\n",
      "mel_emb.conv1d_2.0.weight tensor(0.)\n",
      "mel_emb.conv1d_2.0.bias tensor(0.)\n",
      "mel_emb.out_linear.weight tensor(0.)\n",
      "mel_emb.out_linear.bias tensor(0.)\n",
      "mel_emb.speaker_linear.weight tensor(0.)\n",
      "mel_emb.speaker_linear.bias tensor(0.)\n",
      "decoder.position_enc tensor(0.)\n",
      "decoder.layer_stack.0.slf_attn.w_qs.weight tensor(0.)\n",
      "decoder.layer_stack.0.slf_attn.w_qs.bias tensor(0.)\n",
      "decoder.layer_stack.0.slf_attn.w_ks.weight tensor(0.)\n",
      "decoder.layer_stack.0.slf_attn.w_ks.bias tensor(0.)\n",
      "decoder.layer_stack.0.slf_attn.w_vs.weight tensor(0.)\n",
      "decoder.layer_stack.0.slf_attn.w_vs.bias tensor(0.)\n",
      "decoder.layer_stack.0.slf_attn.layer_norm.weight tensor(0.)\n",
      "decoder.layer_stack.0.slf_attn.layer_norm.bias tensor(0.)\n",
      "decoder.layer_stack.0.slf_attn.fc.weight tensor(0.)\n",
      "decoder.layer_stack.0.slf_attn.fc.bias tensor(0.)\n",
      "decoder.layer_stack.0.pos_ffn.w_1.weight tensor(0.)\n",
      "decoder.layer_stack.0.pos_ffn.w_1.bias tensor(0.)\n",
      "decoder.layer_stack.0.pos_ffn.w_2.weight tensor(0.)\n",
      "decoder.layer_stack.0.pos_ffn.w_2.bias tensor(0.)\n",
      "decoder.layer_stack.0.pos_ffn.layer_norm.weight tensor(0.)\n",
      "decoder.layer_stack.0.pos_ffn.layer_norm.bias tensor(0.)\n",
      "decoder.layer_stack.1.slf_attn.w_qs.weight tensor(0.)\n",
      "decoder.layer_stack.1.slf_attn.w_qs.bias tensor(0.)\n",
      "decoder.layer_stack.1.slf_attn.w_ks.weight tensor(0.)\n",
      "decoder.layer_stack.1.slf_attn.w_ks.bias tensor(0.)\n",
      "decoder.layer_stack.1.slf_attn.w_vs.weight tensor(0.)\n",
      "decoder.layer_stack.1.slf_attn.w_vs.bias tensor(0.)\n",
      "decoder.layer_stack.1.slf_attn.layer_norm.weight tensor(0.)\n",
      "decoder.layer_stack.1.slf_attn.layer_norm.bias tensor(0.)\n",
      "decoder.layer_stack.1.slf_attn.fc.weight tensor(0.)\n",
      "decoder.layer_stack.1.slf_attn.fc.bias tensor(0.)\n",
      "decoder.layer_stack.1.pos_ffn.w_1.weight tensor(0.)\n",
      "decoder.layer_stack.1.pos_ffn.w_1.bias tensor(0.)\n",
      "decoder.layer_stack.1.pos_ffn.w_2.weight tensor(0.)\n",
      "decoder.layer_stack.1.pos_ffn.w_2.bias tensor(0.)\n",
      "decoder.layer_stack.1.pos_ffn.layer_norm.weight tensor(0.)\n",
      "decoder.layer_stack.1.pos_ffn.layer_norm.bias tensor(0.)\n",
      "decoder.layer_stack.2.slf_attn.w_qs.weight tensor(0.)\n",
      "decoder.layer_stack.2.slf_attn.w_qs.bias tensor(0.)\n",
      "decoder.layer_stack.2.slf_attn.w_ks.weight tensor(0.)\n",
      "decoder.layer_stack.2.slf_attn.w_ks.bias tensor(0.)\n",
      "decoder.layer_stack.2.slf_attn.w_vs.weight tensor(0.)\n",
      "decoder.layer_stack.2.slf_attn.w_vs.bias tensor(0.)\n",
      "decoder.layer_stack.2.slf_attn.layer_norm.weight tensor(0.)\n",
      "decoder.layer_stack.2.slf_attn.layer_norm.bias tensor(0.)\n",
      "decoder.layer_stack.2.slf_attn.fc.weight tensor(0.)\n",
      "decoder.layer_stack.2.slf_attn.fc.bias tensor(0.)\n",
      "decoder.layer_stack.2.pos_ffn.w_1.weight tensor(0.)\n",
      "decoder.layer_stack.2.pos_ffn.w_1.bias tensor(0.)\n",
      "decoder.layer_stack.2.pos_ffn.w_2.weight tensor(0.)\n",
      "decoder.layer_stack.2.pos_ffn.w_2.bias tensor(0.)\n",
      "decoder.layer_stack.2.pos_ffn.layer_norm.weight tensor(0.)\n",
      "decoder.layer_stack.2.pos_ffn.layer_norm.bias tensor(0.)\n",
      "decoder.layer_stack.3.slf_attn.w_qs.weight tensor(0.)\n",
      "decoder.layer_stack.3.slf_attn.w_qs.bias tensor(0.)\n",
      "decoder.layer_stack.3.slf_attn.w_ks.weight tensor(0.)\n",
      "decoder.layer_stack.3.slf_attn.w_ks.bias tensor(0.)\n",
      "decoder.layer_stack.3.slf_attn.w_vs.weight tensor(0.)\n",
      "decoder.layer_stack.3.slf_attn.w_vs.bias tensor(0.)\n",
      "decoder.layer_stack.3.slf_attn.layer_norm.weight tensor(0.)\n",
      "decoder.layer_stack.3.slf_attn.layer_norm.bias tensor(0.)\n",
      "decoder.layer_stack.3.slf_attn.fc.weight tensor(0.)\n",
      "decoder.layer_stack.3.slf_attn.fc.bias tensor(0.)\n",
      "decoder.layer_stack.3.pos_ffn.w_1.weight tensor(0.)\n",
      "decoder.layer_stack.3.pos_ffn.w_1.bias tensor(0.)\n",
      "decoder.layer_stack.3.pos_ffn.w_2.weight tensor(0.)\n",
      "decoder.layer_stack.3.pos_ffn.w_2.bias tensor(0.)\n",
      "decoder.layer_stack.3.pos_ffn.layer_norm.weight tensor(0.)\n",
      "decoder.layer_stack.3.pos_ffn.layer_norm.bias tensor(0.)\n",
      "decoder.layer_stack.4.slf_attn.w_qs.weight tensor(0.)\n",
      "decoder.layer_stack.4.slf_attn.w_qs.bias tensor(0.)\n",
      "decoder.layer_stack.4.slf_attn.w_ks.weight tensor(0.)\n",
      "decoder.layer_stack.4.slf_attn.w_ks.bias tensor(0.)\n",
      "decoder.layer_stack.4.slf_attn.w_vs.weight tensor(0.)\n",
      "decoder.layer_stack.4.slf_attn.w_vs.bias tensor(0.)\n",
      "decoder.layer_stack.4.slf_attn.layer_norm.weight tensor(0.)\n",
      "decoder.layer_stack.4.slf_attn.layer_norm.bias tensor(0.)\n",
      "decoder.layer_stack.4.slf_attn.fc.weight tensor(0.)\n",
      "decoder.layer_stack.4.slf_attn.fc.bias tensor(0.)\n",
      "decoder.layer_stack.4.pos_ffn.w_1.weight tensor(0.)\n",
      "decoder.layer_stack.4.pos_ffn.w_1.bias tensor(0.)\n",
      "decoder.layer_stack.4.pos_ffn.w_2.weight tensor(0.)\n",
      "decoder.layer_stack.4.pos_ffn.w_2.bias tensor(0.)\n",
      "decoder.layer_stack.4.pos_ffn.layer_norm.weight tensor(0.)\n",
      "decoder.layer_stack.4.pos_ffn.layer_norm.bias tensor(0.)\n",
      "decoder.layer_stack.5.slf_attn.w_qs.weight tensor(0.)\n",
      "decoder.layer_stack.5.slf_attn.w_qs.bias tensor(0.)\n",
      "decoder.layer_stack.5.slf_attn.w_ks.weight tensor(0.)\n",
      "decoder.layer_stack.5.slf_attn.w_ks.bias tensor(0.)\n",
      "decoder.layer_stack.5.slf_attn.w_vs.weight tensor(0.)\n",
      "decoder.layer_stack.5.slf_attn.w_vs.bias tensor(0.)\n",
      "decoder.layer_stack.5.slf_attn.layer_norm.weight tensor(0.)\n",
      "decoder.layer_stack.5.slf_attn.layer_norm.bias tensor(0.)\n",
      "decoder.layer_stack.5.slf_attn.fc.weight tensor(0.)\n",
      "decoder.layer_stack.5.slf_attn.fc.bias tensor(0.)\n",
      "decoder.layer_stack.5.pos_ffn.w_1.weight tensor(0.)\n",
      "decoder.layer_stack.5.pos_ffn.w_1.bias tensor(0.)\n",
      "decoder.layer_stack.5.pos_ffn.w_2.weight tensor(0.)\n",
      "decoder.layer_stack.5.pos_ffn.w_2.bias tensor(0.)\n",
      "decoder.layer_stack.5.pos_ffn.layer_norm.weight tensor(0.)\n",
      "decoder.layer_stack.5.pos_ffn.layer_norm.bias tensor(0.)\n",
      "mel_linear.weight tensor(0.)\n",
      "mel_linear.bias tensor(0.)\n",
      "postnet.convolutions.0.0.conv.weight tensor(0.)\n",
      "postnet.convolutions.0.0.conv.bias tensor(0.)\n",
      "postnet.convolutions.0.1.weight tensor(0.)\n",
      "postnet.convolutions.0.1.bias tensor(0.)\n",
      "postnet.convolutions.1.0.conv.weight tensor(0.)\n",
      "postnet.convolutions.1.0.conv.bias tensor(0.)\n",
      "postnet.convolutions.1.1.weight tensor(0.)\n",
      "postnet.convolutions.1.1.bias tensor(0.)\n",
      "postnet.convolutions.2.0.conv.weight tensor(0.)\n",
      "postnet.convolutions.2.0.conv.bias tensor(0.)\n",
      "postnet.convolutions.2.1.weight tensor(0.)\n",
      "postnet.convolutions.2.1.bias tensor(0.)\n",
      "postnet.convolutions.3.0.conv.weight tensor(0.)\n",
      "postnet.convolutions.3.0.conv.bias tensor(0.)\n",
      "postnet.convolutions.3.1.weight tensor(0.)\n",
      "postnet.convolutions.3.1.bias tensor(0.)\n",
      "postnet.convolutions.4.0.conv.weight tensor(0.)\n",
      "postnet.convolutions.4.0.conv.bias tensor(0.)\n",
      "postnet.convolutions.4.1.weight tensor(0.)\n",
      "postnet.convolutions.4.1.bias tensor(0.)\n",
      "postnet_decoder.flows.0.logs tensor(0.)\n",
      "postnet_decoder.flows.0.bias tensor(0.)\n",
      "postnet_decoder.flows.1.weight tensor(0.)\n",
      "postnet_decoder.flows.2.start.bias tensor(0.)\n",
      "postnet_decoder.flows.2.start.weight_g tensor(0.)\n",
      "postnet_decoder.flows.2.start.weight_v tensor(0.)\n",
      "postnet_decoder.flows.2.end.weight tensor(0.)\n",
      "postnet_decoder.flows.2.end.bias tensor(0.)\n",
      "postnet_decoder.flows.2.wn.in_layers.0.bias tensor(0.)\n",
      "postnet_decoder.flows.2.wn.in_layers.0.weight_g tensor(0.)\n",
      "postnet_decoder.flows.2.wn.in_layers.0.weight_v tensor(0.)\n",
      "postnet_decoder.flows.2.wn.in_layers.1.bias tensor(0.)\n",
      "postnet_decoder.flows.2.wn.in_layers.1.weight_g tensor(0.)\n",
      "postnet_decoder.flows.2.wn.in_layers.1.weight_v tensor(0.)\n",
      "postnet_decoder.flows.2.wn.in_layers.2.bias tensor(0.)\n",
      "postnet_decoder.flows.2.wn.in_layers.2.weight_g tensor(0.)\n",
      "postnet_decoder.flows.2.wn.in_layers.2.weight_v tensor(0.)\n",
      "postnet_decoder.flows.2.wn.in_layers.3.bias tensor(0.)\n",
      "postnet_decoder.flows.2.wn.in_layers.3.weight_g tensor(0.)\n",
      "postnet_decoder.flows.2.wn.in_layers.3.weight_v tensor(0.)\n",
      "postnet_decoder.flows.2.wn.in_layers.4.bias tensor(0.)\n",
      "postnet_decoder.flows.2.wn.in_layers.4.weight_g tensor(0.)\n",
      "postnet_decoder.flows.2.wn.in_layers.4.weight_v tensor(0.)\n",
      "postnet_decoder.flows.2.wn.in_layers.5.bias tensor(0.)\n",
      "postnet_decoder.flows.2.wn.in_layers.5.weight_g tensor(0.)\n",
      "postnet_decoder.flows.2.wn.in_layers.5.weight_v tensor(0.)\n",
      "postnet_decoder.flows.2.wn.res_skip_layers.0.bias tensor(0.)\n",
      "postnet_decoder.flows.2.wn.res_skip_layers.0.weight_g tensor(0.)\n",
      "postnet_decoder.flows.2.wn.res_skip_layers.0.weight_v tensor(0.)\n",
      "postnet_decoder.flows.2.wn.res_skip_layers.1.bias tensor(0.)\n",
      "postnet_decoder.flows.2.wn.res_skip_layers.1.weight_g tensor(0.)\n",
      "postnet_decoder.flows.2.wn.res_skip_layers.1.weight_v tensor(0.)\n",
      "postnet_decoder.flows.2.wn.res_skip_layers.2.bias tensor(0.)\n",
      "postnet_decoder.flows.2.wn.res_skip_layers.2.weight_g tensor(0.)\n",
      "postnet_decoder.flows.2.wn.res_skip_layers.2.weight_v tensor(0.)\n",
      "postnet_decoder.flows.2.wn.res_skip_layers.3.bias tensor(0.)\n",
      "postnet_decoder.flows.2.wn.res_skip_layers.3.weight_g tensor(0.)\n",
      "postnet_decoder.flows.2.wn.res_skip_layers.3.weight_v tensor(0.)\n",
      "postnet_decoder.flows.2.wn.res_skip_layers.4.bias tensor(0.)\n",
      "postnet_decoder.flows.2.wn.res_skip_layers.4.weight_g tensor(0.)\n",
      "postnet_decoder.flows.2.wn.res_skip_layers.4.weight_v tensor(0.)\n",
      "postnet_decoder.flows.2.wn.res_skip_layers.5.bias tensor(0.)\n",
      "postnet_decoder.flows.2.wn.res_skip_layers.5.weight_g tensor(0.)\n",
      "postnet_decoder.flows.2.wn.res_skip_layers.5.weight_v tensor(0.)\n",
      "postnet_decoder.flows.2.wn.cond_layer.bias tensor(0.)\n",
      "postnet_decoder.flows.2.wn.cond_layer.weight_g tensor(0.)\n",
      "postnet_decoder.flows.2.wn.cond_layer.weight_v tensor(0.)\n",
      "postnet_decoder.flows.3.logs tensor(0.)\n",
      "postnet_decoder.flows.3.bias tensor(0.)\n",
      "postnet_decoder.flows.4.weight tensor(0.)\n",
      "postnet_decoder.flows.5.start.bias tensor(0.)\n",
      "postnet_decoder.flows.5.start.weight_g tensor(0.)\n",
      "postnet_decoder.flows.5.start.weight_v tensor(0.)\n",
      "postnet_decoder.flows.5.end.weight tensor(0.)\n",
      "postnet_decoder.flows.5.end.bias tensor(0.)\n",
      "postnet_decoder.flows.5.wn.in_layers.0.bias tensor(0.)\n",
      "postnet_decoder.flows.5.wn.in_layers.0.weight_g tensor(0.)\n",
      "postnet_decoder.flows.5.wn.in_layers.0.weight_v tensor(0.)\n",
      "postnet_decoder.flows.5.wn.in_layers.1.bias tensor(0.)\n",
      "postnet_decoder.flows.5.wn.in_layers.1.weight_g tensor(0.)\n",
      "postnet_decoder.flows.5.wn.in_layers.1.weight_v tensor(0.)\n",
      "postnet_decoder.flows.5.wn.in_layers.2.bias tensor(0.)\n",
      "postnet_decoder.flows.5.wn.in_layers.2.weight_g tensor(0.)\n",
      "postnet_decoder.flows.5.wn.in_layers.2.weight_v tensor(0.)\n",
      "postnet_decoder.flows.5.wn.in_layers.3.bias tensor(0.)\n",
      "postnet_decoder.flows.5.wn.in_layers.3.weight_g tensor(0.)\n",
      "postnet_decoder.flows.5.wn.in_layers.3.weight_v tensor(0.)\n",
      "postnet_decoder.flows.5.wn.in_layers.4.bias tensor(0.)\n",
      "postnet_decoder.flows.5.wn.in_layers.4.weight_g tensor(0.)\n",
      "postnet_decoder.flows.5.wn.in_layers.4.weight_v tensor(0.)\n",
      "postnet_decoder.flows.5.wn.in_layers.5.bias tensor(0.)\n",
      "postnet_decoder.flows.5.wn.in_layers.5.weight_g tensor(0.)\n",
      "postnet_decoder.flows.5.wn.in_layers.5.weight_v tensor(0.)\n",
      "postnet_decoder.flows.5.wn.res_skip_layers.0.bias tensor(0.)\n",
      "postnet_decoder.flows.5.wn.res_skip_layers.0.weight_g tensor(0.)\n",
      "postnet_decoder.flows.5.wn.res_skip_layers.0.weight_v tensor(0.)\n",
      "postnet_decoder.flows.5.wn.res_skip_layers.1.bias tensor(0.)\n",
      "postnet_decoder.flows.5.wn.res_skip_layers.1.weight_g tensor(0.)\n",
      "postnet_decoder.flows.5.wn.res_skip_layers.1.weight_v tensor(0.)\n",
      "postnet_decoder.flows.5.wn.res_skip_layers.2.bias tensor(0.)\n",
      "postnet_decoder.flows.5.wn.res_skip_layers.2.weight_g tensor(0.)\n",
      "postnet_decoder.flows.5.wn.res_skip_layers.2.weight_v tensor(0.)\n",
      "postnet_decoder.flows.5.wn.res_skip_layers.3.bias tensor(0.)\n",
      "postnet_decoder.flows.5.wn.res_skip_layers.3.weight_g tensor(0.)\n",
      "postnet_decoder.flows.5.wn.res_skip_layers.3.weight_v tensor(0.)\n",
      "postnet_decoder.flows.5.wn.res_skip_layers.4.bias tensor(0.)\n",
      "postnet_decoder.flows.5.wn.res_skip_layers.4.weight_g tensor(0.)\n",
      "postnet_decoder.flows.5.wn.res_skip_layers.4.weight_v tensor(0.)\n",
      "postnet_decoder.flows.5.wn.res_skip_layers.5.bias tensor(0.)\n",
      "postnet_decoder.flows.5.wn.res_skip_layers.5.weight_g tensor(0.)\n",
      "postnet_decoder.flows.5.wn.res_skip_layers.5.weight_v tensor(0.)\n",
      "postnet_decoder.flows.5.wn.cond_layer.bias tensor(0.)\n",
      "postnet_decoder.flows.5.wn.cond_layer.weight_g tensor(0.)\n",
      "postnet_decoder.flows.5.wn.cond_layer.weight_v tensor(0.)\n",
      "postnet_decoder.flows.6.logs tensor(0.)\n",
      "postnet_decoder.flows.6.bias tensor(0.)\n",
      "postnet_decoder.flows.7.weight tensor(0.)\n",
      "postnet_decoder.flows.8.start.bias tensor(0.)\n",
      "postnet_decoder.flows.8.start.weight_g tensor(0.)\n",
      "postnet_decoder.flows.8.start.weight_v tensor(0.)\n",
      "postnet_decoder.flows.8.end.weight tensor(0.)\n",
      "postnet_decoder.flows.8.end.bias tensor(0.)\n",
      "postnet_decoder.flows.8.wn.in_layers.0.bias tensor(0.)\n",
      "postnet_decoder.flows.8.wn.in_layers.0.weight_g tensor(0.)\n",
      "postnet_decoder.flows.8.wn.in_layers.0.weight_v tensor(0.)\n",
      "postnet_decoder.flows.8.wn.in_layers.1.bias tensor(0.)\n",
      "postnet_decoder.flows.8.wn.in_layers.1.weight_g tensor(0.)\n",
      "postnet_decoder.flows.8.wn.in_layers.1.weight_v tensor(0.)\n",
      "postnet_decoder.flows.8.wn.in_layers.2.bias tensor(0.)\n",
      "postnet_decoder.flows.8.wn.in_layers.2.weight_g tensor(0.)\n",
      "postnet_decoder.flows.8.wn.in_layers.2.weight_v tensor(0.)\n",
      "postnet_decoder.flows.8.wn.in_layers.3.bias tensor(0.)\n",
      "postnet_decoder.flows.8.wn.in_layers.3.weight_g tensor(0.)\n",
      "postnet_decoder.flows.8.wn.in_layers.3.weight_v tensor(0.)\n",
      "postnet_decoder.flows.8.wn.in_layers.4.bias tensor(0.)\n",
      "postnet_decoder.flows.8.wn.in_layers.4.weight_g tensor(0.)\n",
      "postnet_decoder.flows.8.wn.in_layers.4.weight_v tensor(0.)\n",
      "postnet_decoder.flows.8.wn.in_layers.5.bias tensor(0.)\n",
      "postnet_decoder.flows.8.wn.in_layers.5.weight_g tensor(0.)\n",
      "postnet_decoder.flows.8.wn.in_layers.5.weight_v tensor(0.)\n",
      "postnet_decoder.flows.8.wn.res_skip_layers.0.bias tensor(0.)\n",
      "postnet_decoder.flows.8.wn.res_skip_layers.0.weight_g tensor(0.)\n",
      "postnet_decoder.flows.8.wn.res_skip_layers.0.weight_v tensor(0.)\n",
      "postnet_decoder.flows.8.wn.res_skip_layers.1.bias tensor(0.)\n",
      "postnet_decoder.flows.8.wn.res_skip_layers.1.weight_g tensor(0.)\n",
      "postnet_decoder.flows.8.wn.res_skip_layers.1.weight_v tensor(0.)\n",
      "postnet_decoder.flows.8.wn.res_skip_layers.2.bias tensor(0.)\n",
      "postnet_decoder.flows.8.wn.res_skip_layers.2.weight_g tensor(0.)\n",
      "postnet_decoder.flows.8.wn.res_skip_layers.2.weight_v tensor(0.)\n",
      "postnet_decoder.flows.8.wn.res_skip_layers.3.bias tensor(0.)\n",
      "postnet_decoder.flows.8.wn.res_skip_layers.3.weight_g tensor(0.)\n",
      "postnet_decoder.flows.8.wn.res_skip_layers.3.weight_v tensor(0.)\n",
      "postnet_decoder.flows.8.wn.res_skip_layers.4.bias tensor(0.)\n",
      "postnet_decoder.flows.8.wn.res_skip_layers.4.weight_g tensor(0.)\n",
      "postnet_decoder.flows.8.wn.res_skip_layers.4.weight_v tensor(0.)\n",
      "postnet_decoder.flows.8.wn.res_skip_layers.5.bias tensor(0.)\n",
      "postnet_decoder.flows.8.wn.res_skip_layers.5.weight_g tensor(0.)\n",
      "postnet_decoder.flows.8.wn.res_skip_layers.5.weight_v tensor(0.)\n",
      "postnet_decoder.flows.8.wn.cond_layer.bias tensor(0.)\n",
      "postnet_decoder.flows.8.wn.cond_layer.weight_g tensor(0.)\n",
      "postnet_decoder.flows.8.wn.cond_layer.weight_v tensor(0.)\n",
      "postnet_decoder.flows.9.logs tensor(0.)\n",
      "postnet_decoder.flows.9.bias tensor(0.)\n",
      "postnet_decoder.flows.10.weight tensor(0.)\n",
      "postnet_decoder.flows.11.start.bias tensor(0.)\n",
      "postnet_decoder.flows.11.start.weight_g tensor(0.)\n",
      "postnet_decoder.flows.11.start.weight_v tensor(0.)\n",
      "postnet_decoder.flows.11.end.weight tensor(0.)\n",
      "postnet_decoder.flows.11.end.bias tensor(0.)\n",
      "postnet_decoder.flows.11.wn.in_layers.0.bias tensor(0.)\n",
      "postnet_decoder.flows.11.wn.in_layers.0.weight_g tensor(0.)\n",
      "postnet_decoder.flows.11.wn.in_layers.0.weight_v tensor(0.)\n",
      "postnet_decoder.flows.11.wn.in_layers.1.bias tensor(0.)\n",
      "postnet_decoder.flows.11.wn.in_layers.1.weight_g tensor(0.)\n",
      "postnet_decoder.flows.11.wn.in_layers.1.weight_v tensor(0.)\n",
      "postnet_decoder.flows.11.wn.in_layers.2.bias tensor(0.)\n",
      "postnet_decoder.flows.11.wn.in_layers.2.weight_g tensor(0.)\n",
      "postnet_decoder.flows.11.wn.in_layers.2.weight_v tensor(0.)\n",
      "postnet_decoder.flows.11.wn.in_layers.3.bias tensor(0.)\n",
      "postnet_decoder.flows.11.wn.in_layers.3.weight_g tensor(0.)\n",
      "postnet_decoder.flows.11.wn.in_layers.3.weight_v tensor(0.)\n",
      "postnet_decoder.flows.11.wn.in_layers.4.bias tensor(0.)\n",
      "postnet_decoder.flows.11.wn.in_layers.4.weight_g tensor(0.)\n",
      "postnet_decoder.flows.11.wn.in_layers.4.weight_v tensor(0.)\n",
      "postnet_decoder.flows.11.wn.in_layers.5.bias tensor(0.)\n",
      "postnet_decoder.flows.11.wn.in_layers.5.weight_g tensor(0.)\n",
      "postnet_decoder.flows.11.wn.in_layers.5.weight_v tensor(0.)\n",
      "postnet_decoder.flows.11.wn.res_skip_layers.0.bias tensor(0.)\n",
      "postnet_decoder.flows.11.wn.res_skip_layers.0.weight_g tensor(0.)\n",
      "postnet_decoder.flows.11.wn.res_skip_layers.0.weight_v tensor(0.)\n",
      "postnet_decoder.flows.11.wn.res_skip_layers.1.bias tensor(0.)\n",
      "postnet_decoder.flows.11.wn.res_skip_layers.1.weight_g tensor(0.)\n",
      "postnet_decoder.flows.11.wn.res_skip_layers.1.weight_v tensor(0.)\n",
      "postnet_decoder.flows.11.wn.res_skip_layers.2.bias tensor(0.)\n",
      "postnet_decoder.flows.11.wn.res_skip_layers.2.weight_g tensor(0.)\n",
      "postnet_decoder.flows.11.wn.res_skip_layers.2.weight_v tensor(0.)\n",
      "postnet_decoder.flows.11.wn.res_skip_layers.3.bias tensor(0.)\n",
      "postnet_decoder.flows.11.wn.res_skip_layers.3.weight_g tensor(0.)\n",
      "postnet_decoder.flows.11.wn.res_skip_layers.3.weight_v tensor(0.)\n",
      "postnet_decoder.flows.11.wn.res_skip_layers.4.bias tensor(0.)\n",
      "postnet_decoder.flows.11.wn.res_skip_layers.4.weight_g tensor(0.)\n",
      "postnet_decoder.flows.11.wn.res_skip_layers.4.weight_v tensor(0.)\n",
      "postnet_decoder.flows.11.wn.res_skip_layers.5.bias tensor(0.)\n",
      "postnet_decoder.flows.11.wn.res_skip_layers.5.weight_g tensor(0.)\n",
      "postnet_decoder.flows.11.wn.res_skip_layers.5.weight_v tensor(0.)\n",
      "postnet_decoder.flows.11.wn.cond_layer.bias tensor(0.)\n",
      "postnet_decoder.flows.11.wn.cond_layer.weight_g tensor(0.)\n",
      "postnet_decoder.flows.11.wn.cond_layer.weight_v tensor(0.)\n",
      "postnet_decoder.flows.12.logs tensor(0.)\n",
      "postnet_decoder.flows.12.bias tensor(0.)\n",
      "postnet_decoder.flows.13.weight tensor(0.)\n",
      "postnet_decoder.flows.14.start.bias tensor(0.)\n",
      "postnet_decoder.flows.14.start.weight_g tensor(0.)\n",
      "postnet_decoder.flows.14.start.weight_v tensor(0.)\n",
      "postnet_decoder.flows.14.end.weight tensor(0.)\n",
      "postnet_decoder.flows.14.end.bias tensor(0.)\n",
      "postnet_decoder.flows.14.wn.in_layers.0.bias tensor(0.)\n",
      "postnet_decoder.flows.14.wn.in_layers.0.weight_g tensor(0.)\n",
      "postnet_decoder.flows.14.wn.in_layers.0.weight_v tensor(0.)\n",
      "postnet_decoder.flows.14.wn.in_layers.1.bias tensor(0.)\n",
      "postnet_decoder.flows.14.wn.in_layers.1.weight_g tensor(0.)\n",
      "postnet_decoder.flows.14.wn.in_layers.1.weight_v tensor(0.)\n",
      "postnet_decoder.flows.14.wn.in_layers.2.bias tensor(0.)\n",
      "postnet_decoder.flows.14.wn.in_layers.2.weight_g tensor(0.)\n",
      "postnet_decoder.flows.14.wn.in_layers.2.weight_v tensor(0.)\n",
      "postnet_decoder.flows.14.wn.in_layers.3.bias tensor(0.)\n",
      "postnet_decoder.flows.14.wn.in_layers.3.weight_g tensor(0.)\n",
      "postnet_decoder.flows.14.wn.in_layers.3.weight_v tensor(0.)\n",
      "postnet_decoder.flows.14.wn.in_layers.4.bias tensor(0.)\n",
      "postnet_decoder.flows.14.wn.in_layers.4.weight_g tensor(0.)\n",
      "postnet_decoder.flows.14.wn.in_layers.4.weight_v tensor(0.)\n",
      "postnet_decoder.flows.14.wn.in_layers.5.bias tensor(0.)\n",
      "postnet_decoder.flows.14.wn.in_layers.5.weight_g tensor(0.)\n",
      "postnet_decoder.flows.14.wn.in_layers.5.weight_v tensor(0.)\n",
      "postnet_decoder.flows.14.wn.res_skip_layers.0.bias tensor(0.)\n",
      "postnet_decoder.flows.14.wn.res_skip_layers.0.weight_g tensor(0.)\n",
      "postnet_decoder.flows.14.wn.res_skip_layers.0.weight_v tensor(0.)\n",
      "postnet_decoder.flows.14.wn.res_skip_layers.1.bias tensor(0.)\n",
      "postnet_decoder.flows.14.wn.res_skip_layers.1.weight_g tensor(0.)\n",
      "postnet_decoder.flows.14.wn.res_skip_layers.1.weight_v tensor(0.)\n",
      "postnet_decoder.flows.14.wn.res_skip_layers.2.bias tensor(0.)\n",
      "postnet_decoder.flows.14.wn.res_skip_layers.2.weight_g tensor(0.)\n",
      "postnet_decoder.flows.14.wn.res_skip_layers.2.weight_v tensor(0.)\n",
      "postnet_decoder.flows.14.wn.res_skip_layers.3.bias tensor(0.)\n",
      "postnet_decoder.flows.14.wn.res_skip_layers.3.weight_g tensor(0.)\n",
      "postnet_decoder.flows.14.wn.res_skip_layers.3.weight_v tensor(0.)\n",
      "postnet_decoder.flows.14.wn.res_skip_layers.4.bias tensor(0.)\n",
      "postnet_decoder.flows.14.wn.res_skip_layers.4.weight_g tensor(0.)\n",
      "postnet_decoder.flows.14.wn.res_skip_layers.4.weight_v tensor(0.)\n",
      "postnet_decoder.flows.14.wn.res_skip_layers.5.bias tensor(0.)\n",
      "postnet_decoder.flows.14.wn.res_skip_layers.5.weight_g tensor(0.)\n",
      "postnet_decoder.flows.14.wn.res_skip_layers.5.weight_v tensor(0.)\n",
      "postnet_decoder.flows.14.wn.cond_layer.bias tensor(0.)\n",
      "postnet_decoder.flows.14.wn.cond_layer.weight_g tensor(0.)\n",
      "postnet_decoder.flows.14.wn.cond_layer.weight_v tensor(0.)\n",
      "postnet_decoder.flows.15.logs tensor(0.)\n",
      "postnet_decoder.flows.15.bias tensor(0.)\n",
      "postnet_decoder.flows.16.weight tensor(0.)\n",
      "postnet_decoder.flows.17.start.bias tensor(0.)\n",
      "postnet_decoder.flows.17.start.weight_g tensor(0.)\n",
      "postnet_decoder.flows.17.start.weight_v tensor(0.)\n",
      "postnet_decoder.flows.17.end.weight tensor(0.)\n",
      "postnet_decoder.flows.17.end.bias tensor(0.)\n",
      "postnet_decoder.flows.17.wn.in_layers.0.bias tensor(0.)\n",
      "postnet_decoder.flows.17.wn.in_layers.0.weight_g tensor(0.)\n",
      "postnet_decoder.flows.17.wn.in_layers.0.weight_v tensor(0.)\n",
      "postnet_decoder.flows.17.wn.in_layers.1.bias tensor(0.)\n",
      "postnet_decoder.flows.17.wn.in_layers.1.weight_g tensor(0.)\n",
      "postnet_decoder.flows.17.wn.in_layers.1.weight_v tensor(0.)\n",
      "postnet_decoder.flows.17.wn.in_layers.2.bias tensor(0.)\n",
      "postnet_decoder.flows.17.wn.in_layers.2.weight_g tensor(0.)\n",
      "postnet_decoder.flows.17.wn.in_layers.2.weight_v tensor(0.)\n",
      "postnet_decoder.flows.17.wn.in_layers.3.bias tensor(0.)\n",
      "postnet_decoder.flows.17.wn.in_layers.3.weight_g tensor(0.)\n",
      "postnet_decoder.flows.17.wn.in_layers.3.weight_v tensor(0.)\n",
      "postnet_decoder.flows.17.wn.in_layers.4.bias tensor(0.)\n",
      "postnet_decoder.flows.17.wn.in_layers.4.weight_g tensor(0.)\n",
      "postnet_decoder.flows.17.wn.in_layers.4.weight_v tensor(0.)\n",
      "postnet_decoder.flows.17.wn.in_layers.5.bias tensor(0.)\n",
      "postnet_decoder.flows.17.wn.in_layers.5.weight_g tensor(0.)\n",
      "postnet_decoder.flows.17.wn.in_layers.5.weight_v tensor(0.)\n",
      "postnet_decoder.flows.17.wn.res_skip_layers.0.bias tensor(0.)\n",
      "postnet_decoder.flows.17.wn.res_skip_layers.0.weight_g tensor(0.)\n",
      "postnet_decoder.flows.17.wn.res_skip_layers.0.weight_v tensor(0.)\n",
      "postnet_decoder.flows.17.wn.res_skip_layers.1.bias tensor(0.)\n",
      "postnet_decoder.flows.17.wn.res_skip_layers.1.weight_g tensor(0.)\n",
      "postnet_decoder.flows.17.wn.res_skip_layers.1.weight_v tensor(0.)\n",
      "postnet_decoder.flows.17.wn.res_skip_layers.2.bias tensor(0.)\n",
      "postnet_decoder.flows.17.wn.res_skip_layers.2.weight_g tensor(0.)\n",
      "postnet_decoder.flows.17.wn.res_skip_layers.2.weight_v tensor(0.)\n",
      "postnet_decoder.flows.17.wn.res_skip_layers.3.bias tensor(0.)\n",
      "postnet_decoder.flows.17.wn.res_skip_layers.3.weight_g tensor(0.)\n",
      "postnet_decoder.flows.17.wn.res_skip_layers.3.weight_v tensor(0.)\n",
      "postnet_decoder.flows.17.wn.res_skip_layers.4.bias tensor(0.)\n",
      "postnet_decoder.flows.17.wn.res_skip_layers.4.weight_g tensor(0.)\n",
      "postnet_decoder.flows.17.wn.res_skip_layers.4.weight_v tensor(0.)\n",
      "postnet_decoder.flows.17.wn.res_skip_layers.5.bias tensor(0.)\n",
      "postnet_decoder.flows.17.wn.res_skip_layers.5.weight_g tensor(0.)\n",
      "postnet_decoder.flows.17.wn.res_skip_layers.5.weight_v tensor(0.)\n",
      "postnet_decoder.flows.17.wn.cond_layer.bias tensor(0.)\n",
      "postnet_decoder.flows.17.wn.cond_layer.weight_g tensor(0.)\n",
      "postnet_decoder.flows.17.wn.cond_layer.weight_v tensor(0.)\n",
      "speaker_emb.weight tensor(0.)\n",
      "cross_atten.w_qs.weight tensor(0.)\n",
      "cross_atten.w_qs.bias tensor(0.)\n",
      "cross_atten.w_ks.weight tensor(0.)\n",
      "cross_atten.w_ks.bias tensor(0.)\n",
      "cross_atten.w_vs.weight tensor(0.)\n",
      "cross_atten.w_vs.bias tensor(0.)\n",
      "cross_atten.layer_norm.weight tensor(0.)\n",
      "cross_atten.layer_norm.bias tensor(0.)\n",
      "cross_atten.fc.weight tensor(0.)\n",
      "cross_atten.fc.bias tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "compute_model_param_diff(model, model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470f5f7e-dde0-4d81-a18c-3aba80a62452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
